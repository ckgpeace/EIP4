{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4B.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckgpeace/EIP4/blob/master/Assignment4/Assignment4B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOnlcHWa72Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WJVHU7h89OD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 50\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofenJ5_19CeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "64cdd164-f783-4e12-8131-8e532b83efc2"
      },
      "source": [
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTqWUQp1X6zF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjYvZPhA9tzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCG2jO5S995y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUt3q1Nv-A_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=32,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVVA2Rue-gTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 32\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lfNR55v-yqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxlTRRoa_XUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0fb1505-9a63-437b-c72d-36ae2cde1bc9"
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.003\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 32)   896         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 32)   128         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 32, 32, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 32, 32, 32)   9248        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 32, 32, 32)   128         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 32, 32, 32)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 32, 32, 32)   9248        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 32, 32, 32)   128         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 32, 32, 32)   0           activation_102[0][0]             \n",
            "                                                                 batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 32, 32, 32)   0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 32, 32, 32)   9248        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 32, 32, 32)   128         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 32, 32, 32)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 32, 32, 32)   9248        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 32, 32, 32)   128         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 32, 32, 32)   0           activation_104[0][0]             \n",
            "                                                                 batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 32, 32, 32)   0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 32, 32, 32)   9248        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 32, 32, 32)   128         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 32, 32, 32)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 32, 32, 32)   9248        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 32, 32, 32)   128         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 32, 32, 32)   0           activation_106[0][0]             \n",
            "                                                                 batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 32, 32, 32)   0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 64)   18496       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   256         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 16, 16, 64)   36928       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 16, 16, 64)   2112        activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   256         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 16, 16, 64)   0           conv2d_124[0][0]                 \n",
            "                                                                 batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 64)   0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 16, 16, 64)   36928       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 64)   256         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 64)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 16, 16, 64)   36928       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   256         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 16, 16, 64)   0           activation_110[0][0]             \n",
            "                                                                 batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 16, 16, 64)   36928       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   256         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 16, 16, 64)   36928       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 64)   256         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 16, 16, 64)   0           activation_112[0][0]             \n",
            "                                                                 batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 64)   0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 8, 8, 128)    73856       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 8, 8, 128)    512         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 8, 8, 128)    0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 8, 8, 128)    147584      activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 8, 8, 128)    8320        activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 8, 8, 128)    512         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 8, 8, 128)    0           conv2d_131[0][0]                 \n",
            "                                                                 batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 8, 8, 128)    0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 8, 8, 128)    147584      activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 8, 8, 128)    512         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 8, 8, 128)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 8, 8, 128)    147584      activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 8, 8, 128)    512         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 8, 8, 128)    0           activation_116[0][0]             \n",
            "                                                                 batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 8, 8, 128)    0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 8, 8, 128)    147584      activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 8, 8, 128)    512         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 8, 8, 128)    0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 8, 8, 128)    147584      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 8, 8, 128)    512         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 8, 8, 128)    0           activation_118[0][0]             \n",
            "                                                                 batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 8, 8, 128)    0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 1, 1, 128)    0           activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 128)          0           average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 10)           1290        flatten_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,088,522\n",
            "Trainable params: 1,085,770\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzcs9tNF_Xvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5de2fff5-1c66-4f1f-8869-5b3d30d3ee36"
      },
      "source": [
        "print(model_type)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet20v1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEHm8PFKAG_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9AC99vfAK2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd7APdUJAMA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "603b2dea-6e56-4952-dd64-04b4c73fb63b"
      },
      "source": [
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/50\n",
            "Learning rate:  0.003\n",
            "391/391 [==============================] - 39s 101ms/step - loss: 1.7552 - acc: 0.4703 - val_loss: 2.2848 - val_acc: 0.4093\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.40930, saving model to /content/saved_models/cifar10_ResNet20v1_model.001.h5\n",
            "Epoch 2/50\n",
            "Learning rate:  0.0022744503\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 1.2132 - acc: 0.6551 - val_loss: 1.3032 - val_acc: 0.6282\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.40930 to 0.62820, saving model to /content/saved_models/cifar10_ResNet20v1_model.002.h5\n",
            "Epoch 3/50\n",
            "Learning rate:  0.0018315018\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 1.0100 - acc: 0.7307 - val_loss: 1.6597 - val_acc: 0.5474\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.62820\n",
            "Epoch 4/50\n",
            "Learning rate:  0.0015329586\n",
            "391/391 [==============================] - 31s 80ms/step - loss: 0.8894 - acc: 0.7715 - val_loss: 1.0645 - val_acc: 0.7155\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.62820 to 0.71550, saving model to /content/saved_models/cifar10_ResNet20v1_model.004.h5\n",
            "Epoch 5/50\n",
            "Learning rate:  0.0013181019\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.8046 - acc: 0.7983 - val_loss: 1.3296 - val_acc: 0.6707\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.71550\n",
            "Epoch 6/50\n",
            "Learning rate:  0.0011560694\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.7444 - acc: 0.8199 - val_loss: 0.9661 - val_acc: 0.7560\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.71550 to 0.75600, saving model to /content/saved_models/cifar10_ResNet20v1_model.006.h5\n",
            "Epoch 7/50\n",
            "Learning rate:  0.0010295127\n",
            "391/391 [==============================] - 31s 80ms/step - loss: 0.6844 - acc: 0.8365 - val_loss: 1.0145 - val_acc: 0.7446\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.75600\n",
            "Epoch 8/50\n",
            "Learning rate:  0.0009279307\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.6442 - acc: 0.8517 - val_loss: 0.9258 - val_acc: 0.7697\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.75600 to 0.76970, saving model to /content/saved_models/cifar10_ResNet20v1_model.008.h5\n",
            "Epoch 9/50\n",
            "Learning rate:  0.0008445946\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.6085 - acc: 0.8625 - val_loss: 0.7579 - val_acc: 0.8103\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.76970 to 0.81030, saving model to /content/saved_models/cifar10_ResNet20v1_model.009.h5\n",
            "Epoch 10/50\n",
            "Learning rate:  0.0007749935\n",
            "391/391 [==============================] - 31s 80ms/step - loss: 0.5789 - acc: 0.8687 - val_loss: 1.0242 - val_acc: 0.7418\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.81030\n",
            "Epoch 11/50\n",
            "Learning rate:  0.0007159905\n",
            "391/391 [==============================] - 32s 81ms/step - loss: 0.5426 - acc: 0.8809 - val_loss: 0.6856 - val_acc: 0.8294\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.81030 to 0.82940, saving model to /content/saved_models/cifar10_ResNet20v1_model.011.h5\n",
            "Epoch 12/50\n",
            "Learning rate:  0.000665336\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.5182 - acc: 0.8867 - val_loss: 0.6338 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.82940 to 0.85290, saving model to /content/saved_models/cifar10_ResNet20v1_model.012.h5\n",
            "Epoch 13/50\n",
            "Learning rate:  0.0006213753\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.4913 - acc: 0.8967 - val_loss: 0.6383 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.85290\n",
            "Epoch 14/50\n",
            "Learning rate:  0.0005828638\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.4704 - acc: 0.9026 - val_loss: 0.7744 - val_acc: 0.8179\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.85290\n",
            "Epoch 15/50\n",
            "Learning rate:  0.0005488474\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.4532 - acc: 0.9061 - val_loss: 0.6440 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.85290 to 0.85460, saving model to /content/saved_models/cifar10_ResNet20v1_model.015.h5\n",
            "Epoch 16/50\n",
            "Learning rate:  0.0005185825\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.4366 - acc: 0.9121 - val_loss: 0.6598 - val_acc: 0.8481\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.85460\n",
            "Epoch 17/50\n",
            "Learning rate:  0.000491481\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.4157 - acc: 0.9185 - val_loss: 0.6297 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.85460 to 0.85820, saving model to /content/saved_models/cifar10_ResNet20v1_model.017.h5\n",
            "Epoch 18/50\n",
            "Learning rate:  0.0004670715\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.4012 - acc: 0.9223 - val_loss: 0.6057 - val_acc: 0.8632\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.85820 to 0.86320, saving model to /content/saved_models/cifar10_ResNet20v1_model.018.h5\n",
            "Epoch 19/50\n",
            "Learning rate:  0.0004449718\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.3875 - acc: 0.9261 - val_loss: 0.5520 - val_acc: 0.8737\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.86320 to 0.87370, saving model to /content/saved_models/cifar10_ResNet20v1_model.019.h5\n",
            "Epoch 20/50\n",
            "Learning rate:  0.000424869\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.3776 - acc: 0.9284 - val_loss: 0.6052 - val_acc: 0.8605\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.87370\n",
            "Epoch 21/50\n",
            "Learning rate:  0.0004065041\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.3625 - acc: 0.9339 - val_loss: 0.5787 - val_acc: 0.8730\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.87370\n",
            "Epoch 22/50\n",
            "Learning rate:  0.000389661\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.3517 - acc: 0.9363 - val_loss: 0.6693 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.87370\n",
            "Epoch 23/50\n",
            "Learning rate:  0.0003741581\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.3379 - acc: 0.9408 - val_loss: 0.6696 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.87370\n",
            "Epoch 24/50\n",
            "Learning rate:  0.0003598417\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.3240 - acc: 0.9447 - val_loss: 0.5945 - val_acc: 0.8733\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.87370\n",
            "Epoch 25/50\n",
            "Learning rate:  0.0003465804\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 0.3188 - acc: 0.9468 - val_loss: 0.5871 - val_acc: 0.8762\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.87370 to 0.87620, saving model to /content/saved_models/cifar10_ResNet20v1_model.025.h5\n",
            "Epoch 26/50\n",
            "Learning rate:  0.0003342618\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.3096 - acc: 0.9492 - val_loss: 0.5257 - val_acc: 0.8879\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.87620 to 0.88790, saving model to /content/saved_models/cifar10_ResNet20v1_model.026.h5\n",
            "Epoch 27/50\n",
            "Learning rate:  0.0003227889\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.3034 - acc: 0.9506 - val_loss: 0.5465 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.88790\n",
            "Epoch 28/50\n",
            "Learning rate:  0.0003120774\n",
            "391/391 [==============================] - 31s 80ms/step - loss: 0.2917 - acc: 0.9534 - val_loss: 0.5962 - val_acc: 0.8746\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.88790\n",
            "Epoch 29/50\n",
            "Learning rate:  0.000302054\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.2860 - acc: 0.9559 - val_loss: 0.6169 - val_acc: 0.8731\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.88790\n",
            "Epoch 30/50\n",
            "Learning rate:  0.0002926544\n",
            "391/391 [==============================] - 31s 80ms/step - loss: 0.2777 - acc: 0.9577 - val_loss: 0.5740 - val_acc: 0.8814\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.88790\n",
            "Epoch 31/50\n",
            "Learning rate:  0.0002838221\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.2704 - acc: 0.9599 - val_loss: 0.5899 - val_acc: 0.8799\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.88790\n",
            "Epoch 32/50\n",
            "Learning rate:  0.0002755074\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.2633 - acc: 0.9619 - val_loss: 0.6250 - val_acc: 0.8748\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.88790\n",
            "Epoch 33/50\n",
            "Learning rate:  0.000267666\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.2619 - acc: 0.9621 - val_loss: 0.6094 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.88790\n",
            "Epoch 34/50\n",
            "Learning rate:  0.0002602585\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.2482 - acc: 0.9656 - val_loss: 0.5834 - val_acc: 0.8802\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.88790\n",
            "Epoch 35/50\n",
            "Learning rate:  0.00025325\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.2458 - acc: 0.9664 - val_loss: 0.5912 - val_acc: 0.8811\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.88790\n",
            "Epoch 36/50\n",
            "Learning rate:  0.0002466091\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.2437 - acc: 0.9676 - val_loss: 0.6027 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.88790\n",
            "Epoch 37/50\n",
            "Learning rate:  0.0002403076\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.2384 - acc: 0.9675 - val_loss: 0.5487 - val_acc: 0.8914\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.88790 to 0.89140, saving model to /content/saved_models/cifar10_ResNet20v1_model.037.h5\n",
            "Epoch 38/50\n",
            "Learning rate:  0.0002343201\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.2322 - acc: 0.9706 - val_loss: 0.5697 - val_acc: 0.8853\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.89140\n",
            "Epoch 39/50\n",
            "Learning rate:  0.0002286237\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.2278 - acc: 0.9712 - val_loss: 0.5880 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.89140\n",
            "Epoch 40/50\n",
            "Learning rate:  0.0002231977\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.2226 - acc: 0.9732 - val_loss: 0.5553 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.89140\n",
            "Epoch 41/50\n",
            "Learning rate:  0.0002180233\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.2183 - acc: 0.9738 - val_loss: 0.5929 - val_acc: 0.8841\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.89140\n",
            "Epoch 42/50\n",
            "Learning rate:  0.0002130833\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.2132 - acc: 0.9750 - val_loss: 0.5174 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.89140 to 0.90210, saving model to /content/saved_models/cifar10_ResNet20v1_model.042.h5\n",
            "Epoch 43/50\n",
            "Learning rate:  0.0002083623\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.2107 - acc: 0.9757 - val_loss: 0.5998 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.90210\n",
            "Epoch 44/50\n",
            "Learning rate:  0.0002038459\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.2086 - acc: 0.9759 - val_loss: 0.5954 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.90210\n",
            "Epoch 45/50\n",
            "Learning rate:  0.0001995211\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.2037 - acc: 0.9776 - val_loss: 0.5865 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.90210\n",
            "Epoch 46/50\n",
            "Learning rate:  0.0001953761\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.2018 - acc: 0.9779 - val_loss: 0.5864 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.90210\n",
            "Epoch 47/50\n",
            "Learning rate:  0.0001913998\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.1998 - acc: 0.9789 - val_loss: 0.5728 - val_acc: 0.8941\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.90210\n",
            "Epoch 48/50\n",
            "Learning rate:  0.0001875821\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.1988 - acc: 0.9779 - val_loss: 0.6774 - val_acc: 0.8701\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.90210\n",
            "Epoch 49/50\n",
            "Learning rate:  0.0001839137\n",
            "391/391 [==============================] - 31s 78ms/step - loss: 0.1925 - acc: 0.9808 - val_loss: 0.5202 - val_acc: 0.9012\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.90210\n",
            "Epoch 50/50\n",
            "Learning rate:  0.000180386\n",
            "391/391 [==============================] - 31s 79ms/step - loss: 0.1888 - acc: 0.9816 - val_loss: 0.5661 - val_acc: 0.8968\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.90210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmVJAtmKAO4U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f5dca49d-6489-449a-d0e7-32d97c8cbf55"
      },
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 246us/step\n",
            "Test loss: 0.5661127030849457\n",
            "Test accuracy: 0.8968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4uK136GKf63",
        "colab_type": "text"
      },
      "source": [
        "## GRADCAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ3jiZV3KdBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eMVCv8XKjfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_nbr = 289\n",
        "model = model\n",
        "from skimage import io\n",
        "img = X_train[image_nbr]\n",
        "img = cv2.resize(img, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "893vuNAyKj8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9ca91e1-bf04-40f5-d01d-86a828cb4fd6"
      },
      "source": [
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_135\")"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9LXQHiPKkDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8e54baf0-4448-4802-8201-ba8ee40096fd"
      },
      "source": [
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "for i in range(128):\n",
        "  conv_layer_output_value[:, :, i] *= pooled_grads_value[i]"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 8, 8, 128)\n",
            "(128,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k5znNr3Kr9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "05890450-a2df-45fe-d14c-5246b883049c"
      },
      "source": [
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 8, 128)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuFBtBtuKw-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "2bcf00eb-36f6-4549-8294-a9f4114f85d2"
      },
      "source": [
        "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(img, 0.5, heatmap, 0.5, 0, dtype = cv2.CV_32F)\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "%matplotlib inline\n",
        "cv2_imshow(cv2.resize(img, (128,128)))\n",
        "cv2_imshow(cv2.resize(superimposed_img, (128,128)))"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAABDNklEQVR4nI29a3rjyM4miEsEKdnO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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCE746024E0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAA7jUlEQVR4nO2924LstpIltlYAZGZt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\ndfxPPP4/4UpsTrjel2oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCE746023C8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtWVkZ_5mseb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}