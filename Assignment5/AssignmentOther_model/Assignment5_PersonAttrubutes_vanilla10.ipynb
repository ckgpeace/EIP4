{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5_PersonAttrubutes_vanilla10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckgpeace/EIP4/blob/master/Assignment5/AssignmentOther_model/Assignment5_PersonAttrubutes_vanilla10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El-Dopn8pLpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "outputId": "4a2c1159-05ad-45ff-c804-28d044eecc39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  hvc_annotations.csv  \u001b[01;34mresized\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "outputId": "b9a8667a-baa1-40bf-a71a-6511ed2840e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout, GlobalAveragePooling2D, AveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, SeparableConv2D\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "outputId": "bfd92d5a-a43c-4134-e6dd-78dc0f954a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>imagequality</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>carryingbag</th>\n",
              "      <th>footwear</th>\n",
              "      <th>emotion</th>\n",
              "      <th>bodypose</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>over-weight</td>\n",
              "      <td>None</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Angry/Serious</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Daily/Office/Work Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>Good</td>\n",
              "      <td>35-45</td>\n",
              "      <td>slightly-overweight</td>\n",
              "      <td>None</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender imagequality    age  ...        emotion        bodypose     image_path\n",
              "0    male      Average  35-45  ...        Neutral  Front-Frontish  resized/1.jpg\n",
              "1  female      Average  35-45  ...  Angry/Serious  Front-Frontish  resized/2.jpg\n",
              "2    male         Good  45-55  ...        Neutral  Front-Frontish  resized/3.jpg\n",
              "3    male         Good  45-55  ...        Neutral  Front-Frontish  resized/4.jpg\n",
              "4  female         Good  35-45  ...        Neutral  Front-Frontish  resized/5.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "outputId": "15439bac-4953-4806-95a1-b36ab320e64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>image_path</th>\n",
              "      <td>resized/1.jpg</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_female</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_male</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Average</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Good</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_15-25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_25-35</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_35-45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_45-55</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_55+</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_over-weight</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_underweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_None</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Normal</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Happy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Sad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Back</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Side</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  0  ...              4\n",
              "image_path                            resized/1.jpg  ...  resized/5.jpg\n",
              "gender_female                                     0  ...              1\n",
              "gender_male                                       1  ...              0\n",
              "imagequality_Average                              1  ...              0\n",
              "imagequality_Bad                                  0  ...              0\n",
              "imagequality_Good                                 0  ...              1\n",
              "age_15-25                                         0  ...              0\n",
              "age_25-35                                         0  ...              0\n",
              "age_35-45                                         1  ...              1\n",
              "age_45-55                                         0  ...              0\n",
              "age_55+                                           0  ...              0\n",
              "weight_normal-healthy                             1  ...              0\n",
              "weight_over-weight                                0  ...              0\n",
              "weight_slightly-overweight                        0  ...              1\n",
              "weight_underweight                                0  ...              0\n",
              "carryingbag_Daily/Office/Work Bag                 0  ...              0\n",
              "carryingbag_Grocery/Home/Plastic Bag              1  ...              0\n",
              "carryingbag_None                                  0  ...              1\n",
              "footwear_CantSee                                  0  ...              1\n",
              "footwear_Fancy                                    0  ...              0\n",
              "footwear_Normal                                   1  ...              0\n",
              "emotion_Angry/Serious                             0  ...              0\n",
              "emotion_Happy                                     0  ...              0\n",
              "emotion_Neutral                                   1  ...              1\n",
              "emotion_Sad                                       0  ...              0\n",
              "bodypose_Back                                     0  ...              0\n",
              "bodypose_Front-Frontish                           1  ...              1\n",
              "bodypose_Side                                     0  ...              0\n",
              "\n",
              "[28 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=64, shuffle=True, augmentation = None):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.resize(cv2.imread(item[\"image_path\"]), (112,112)) for _, item in items.iterrows()])\n",
        "        #Image Normalization\n",
        "        if self.augmentation is not None:\n",
        "          self.augmentation.fit(image)\n",
        "          image = self.augmentation.flow(image,shuffle=False, batch_size = 64 ).next()\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "outputId": "e379aaba-8a21-47c8-a0c3-9ec8d4c81ac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15, random_state = 404)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11537, 28), (2036, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "outputId": "25e120e9-9708-4b93-b784-932b3e86999e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>gender_female</th>\n",
              "      <th>gender_male</th>\n",
              "      <th>imagequality_Average</th>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <th>imagequality_Good</th>\n",
              "      <th>age_15-25</th>\n",
              "      <th>age_25-35</th>\n",
              "      <th>age_35-45</th>\n",
              "      <th>age_45-55</th>\n",
              "      <th>age_55+</th>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <th>weight_over-weight</th>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <th>weight_underweight</th>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <th>carryingbag_None</th>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <th>footwear_Normal</th>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <th>emotion_Happy</th>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <th>emotion_Sad</th>\n",
              "      <th>bodypose_Back</th>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <th>bodypose_Side</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10980</th>\n",
              "      <td>resized/10982.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11135</th>\n",
              "      <td>resized/11137.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1784</th>\n",
              "      <td>resized/1785.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7758</th>\n",
              "      <td>resized/7759.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4692</th>\n",
              "      <td>resized/4693.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              image_path  gender_female  ...  bodypose_Front-Frontish  bodypose_Side\n",
              "10980  resized/10982.jpg              0  ...                        1              0\n",
              "11135  resized/11137.jpg              0  ...                        0              1\n",
              "1784    resized/1785.jpg              0  ...                        1              0\n",
              "7758    resized/7759.jpg              0  ...                        0              1\n",
              "4692    resized/4693.jpg              0  ...                        1              0\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=64, shuffle=True, \n",
        "                                augmentation = ImageDataGenerator(horizontal_flip=True, \n",
        "                                                                  width_shift_range=0.2,\n",
        "                                                                  height_shift_range=0.2,\n",
        "                                                                  rotation_range=0,\n",
        "                                                                  zoom_range=0.2,\n",
        "                                                                  featurewise_center=True, featurewise_std_normalization=True))\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=64, shuffle=False, augmentation= ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "outputId": "1230078f-0c62-42e4-def1-674267cbad3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 5,\n",
              " 'bag': 3,\n",
              " 'emotion': 4,\n",
              " 'footwear': 3,\n",
              " 'gender': 2,\n",
              " 'image_quality': 3,\n",
              " 'pose': 3,\n",
              " 'weight': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03W8Pagg_Ppp",
        "colab_type": "code",
        "outputId": "8c016b7e-9c19-44ab-8449-cc6dc37ba33f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "## Current - vanilla10\n",
        "\n",
        "inp = Input(shape = (112,112,3))\n",
        "x = inp\n",
        "### block 1\n",
        "\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Pooling \n",
        "x = AveragePooling2D()(x)\n",
        "\n",
        "# ================================================================\n",
        "\n",
        "### block\n",
        "\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Pooling \n",
        "x = AveragePooling2D()(x)\n",
        "\n",
        "# ================================================================\n",
        "\n",
        "### block 2 \n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), padding='valid')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=256, kernel_size=(3, 3), padding='valid')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.05)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=256, kernel_size=(3, 3), padding='valid')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.05)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Pooling \n",
        "x = AveragePooling2D()(x)\n",
        "\n",
        "# ================================================================\n",
        "# block  - Last CNN\n",
        "\n",
        "x = SeparableConv2D(filters=512, kernel_size=(3, 3), padding='valid')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=512, kernel_size=(3, 3), padding='valid')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "\n",
        "# Adding Dense layer\n",
        "def final(in_layer, num_units, class_name, output_name):\n",
        "  # Conv with class size\n",
        "  x = SeparableConv2D(filters=num_units[class_name], kernel_size=(1, 1), padding='valid')(in_layer)\n",
        "  # GAP\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Activation('softmax', name = output_name)(x)\n",
        "  return x\n",
        "\n",
        "gender = final(in_layer = x, num_units = num_units,  class_name = \"gender\", output_name = \"gender_output\")\n",
        "image_quality = final(in_layer = x, num_units = num_units,  class_name = \"image_quality\", output_name = \"image_quality_output\")\n",
        "age = final(in_layer = x, num_units = num_units,  class_name = \"age\", output_name = \"age_output\")\n",
        "weight = final(in_layer = x, num_units = num_units,  class_name = \"weight\", output_name = \"weight_output\")\n",
        "bag = final(in_layer = x, num_units = num_units,  class_name = \"bag\", output_name = \"bag_output\")\n",
        "footwear = final(in_layer = x, num_units = num_units,  class_name = \"footwear\", output_name = \"footwear_output\")\n",
        "emotion = final(in_layer = x, num_units = num_units,  class_name = \"emotion\", output_name = \"emotion_output\")\n",
        "pose = final(in_layer = x, num_units = num_units,  class_name = \"pose\", output_name = \"pose_output\")\n",
        "\n",
        "model = Model(inputs = inp,outputs=[gender, image_quality, age, weight, bag, pose, footwear, emotion])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 112, 112, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_123 (Separable (None, 110, 110, 32) 155         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 110, 110, 32) 0           separable_conv2d_123[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 110, 110, 32) 128         activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_124 (Separable (None, 108, 108, 32) 1344        batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 108, 108, 32) 0           separable_conv2d_124[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 108, 108, 32) 128         activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_125 (Separable (None, 106, 106, 64) 2400        batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 106, 106, 64) 0           separable_conv2d_125[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 106, 106, 64) 256         activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_126 (Separable (None, 104, 104, 64) 4736        batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 104, 104, 64) 0           separable_conv2d_126[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 104, 104, 64) 256         activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 52, 52, 64)   0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_127 (Separable (None, 50, 50, 64)   4736        average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 50, 50, 64)   0           separable_conv2d_127[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 50, 50, 64)   256         activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_128 (Separable (None, 48, 48, 64)   4736        batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 48, 48, 64)   0           separable_conv2d_128[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 48, 48, 64)   256         activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_129 (Separable (None, 46, 46, 128)  8896        batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 46, 46, 128)  0           separable_conv2d_129[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 46, 46, 128)  512         activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_25 (AveragePo (None, 23, 23, 128)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_130 (Separable (None, 21, 21, 128)  17664       average_pooling2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 21, 21, 128)  0           separable_conv2d_130[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 21, 21, 128)  512         activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_131 (Separable (None, 19, 19, 256)  34176       batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 19, 19, 256)  0           separable_conv2d_131[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 19, 19, 256)  0           activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 19, 19, 256)  1024        dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_132 (Separable (None, 17, 17, 256)  68096       batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 17, 17, 256)  0           separable_conv2d_132[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 17, 17, 256)  0           activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 17, 17, 256)  1024        dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_26 (AveragePo (None, 8, 8, 256)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_133 (Separable (None, 6, 6, 512)    133888      average_pooling2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 512)    0           separable_conv2d_133[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 6, 6, 512)    2048        activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_134 (Separable (None, 4, 4, 512)    267264      batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 4, 4, 512)    0           separable_conv2d_134[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 4, 4, 512)    2048        activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_135 (Separable (None, 4, 4, 2)      1538        batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_136 (Separable (None, 4, 4, 3)      2051        batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_137 (Separable (None, 4, 4, 5)      3077        batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_138 (Separable (None, 4, 4, 4)      2564        batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_139 (Separable (None, 4, 4, 3)      2051        batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_142 (Separable (None, 4, 4, 3)      2051        batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_140 (Separable (None, 4, 4, 3)      2051        batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_141 (Separable (None, 4, 4, 4)      2564        batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_41 (Gl (None, 2)            0           separable_conv2d_135[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_42 (Gl (None, 3)            0           separable_conv2d_136[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_43 (Gl (None, 5)            0           separable_conv2d_137[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_44 (Gl (None, 4)            0           separable_conv2d_138[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_45 (Gl (None, 3)            0           separable_conv2d_139[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_48 (Gl (None, 3)            0           separable_conv2d_142[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_46 (Gl (None, 3)            0           separable_conv2d_140[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_47 (Gl (None, 4)            0           separable_conv2d_141[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Activation)      (None, 2)            0           global_average_pooling2d_41[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "image_quality_output (Activatio (None, 3)            0           global_average_pooling2d_42[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "age_output (Activation)         (None, 5)            0           global_average_pooling2d_43[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "weight_output (Activation)      (None, 4)            0           global_average_pooling2d_44[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "bag_output (Activation)         (None, 3)            0           global_average_pooling2d_45[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "pose_output (Activation)        (None, 3)            0           global_average_pooling2d_48[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "footwear_output (Activation)    (None, 3)            0           global_average_pooling2d_46[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "emotion_output (Activation)     (None, 4)            0           global_average_pooling2d_47[0][0]\n",
            "==================================================================================================\n",
            "Total params: 574,486\n",
            "Trainable params: 570,262\n",
            "Non-trainable params: 4,224\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkqMc7GkN2sl",
        "colab_type": "code",
        "outputId": "9dbdf097-3fca-41ef-eb92-dde34999b2de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from keras.utils import plot_model\n",
        "# plot_model(model)\n",
        "import time, psutil\n",
        "uptime = time.time() - psutil.boot_time()\n",
        "remain = 12*60*60 - uptime\n",
        "remain/(60*60)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.2240886894199585"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1dcoduDN2pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = {\n",
        "\t\"gender_output\": \"categorical_crossentropy\",\n",
        "\t\"image_quality_output\": \"categorical_crossentropy\",\n",
        "\t\"age_output\": \"categorical_crossentropy\",\n",
        "\t\"weight_output\": \"categorical_crossentropy\",\n",
        "  \"bag_output\":  \"categorical_crossentropy\",\n",
        "  \"pose_output\": \"categorical_crossentropy\",\n",
        "  \"footwear_output\": \"categorical_crossentropy\",\n",
        "  \"emotion_output\": \"categorical_crossentropy\"\n",
        "}\n",
        "\n",
        "loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0, \"weight_output\" :1.0,  \"bag_output\": 1.0, \"pose_output\": 1.0,  \"footwear_output\": 1.0, \"emotion_output\": 1.0 }\n",
        "\n",
        "\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "decay_factor = 0.007\n",
        "def scheduler(epoch, lr):\n",
        "  return round(lr * 1/(1 + decay_factor * epoch), 10)\n",
        "\n",
        "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "opt = SGD(lr=0.01, momentum=0.9)\n",
        "\n",
        "model.compile( optimizer=opt, loss = losses, loss_weights=loss_weights, metrics=[\"accuracy\"])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyOyW5EOQAEJ",
        "colab_type": "code",
        "outputId": "77d49b3c-79dd-4a53-8fa9-221e4a9994ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# model_path = '/content/gdrive/VGG16_vanila_1.h5'\n",
        "# checkpoint = ModelCheckpoint(model_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max')\n",
        "\n",
        "import os\n",
        "# Checkpoint saving\n",
        "save_dir = os.path.join(os.getcwd(), \"/gdrive/My\\\\Drive/saved_models/\")\n",
        "model_name = \"model.{epoch:03d}.h5\"\n",
        "if not os.path.isdir(save_dir):\n",
        "  os.makedirs(save_dir)\n",
        "\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "\n",
        "checkpoint = ModelCheckpoint(model_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False)\n",
        "\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=11, verbose=1, mode='min')\n",
        "\n",
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    callbacks=[checkpoint, early, LearningRateScheduler(scheduler, verbose=1)]\n",
        "    # callbacks=[checkpoint, early, LearningRateScheduler(scheduler, verbose=1),TensorBoardColabCallback(tbc)]\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4fe982005707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mearly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ModelCheckpoint' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9Qcz9_GQANw",
        "colab_type": "code",
        "outputId": "ccf2444a-3c22-440f-b76d-91835ec7a452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "def evaluate_model(model):\n",
        "  results = model.evaluate_generator(valid_gen, verbose=1)\n",
        "  accuracies = {}\n",
        "  losses = {}\n",
        "  for k, v in zip(model.metrics_names, results):\n",
        "    if k.endswith('acc'):\n",
        "      accuracies[k] = round(v * 100, 4)\n",
        "    else:\n",
        "      losses[k] = v\n",
        "  return accuracies\n",
        "\n",
        "evaluate_model(model)\n",
        "\n",
        "# results = model.evaluate_generator(valid_gen, verbose =1)\n",
        "# dict(zip(model.metrics_names, results))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 6s 190ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age_output_acc': 40.0706,\n",
              " 'bag_output_acc': 66.1794,\n",
              " 'emotion_output_acc': 73.2863,\n",
              " 'footwear_output_acc': 61.2903,\n",
              " 'gender_output_acc': 85.0302,\n",
              " 'image_quality_output_acc': 51.1593,\n",
              " 'pose_output_acc': 80.3427,\n",
              " 'weight_output_acc': 65.0706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-nJYdSOQAGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,1,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    # axs[0].plot(range(1,len(model_history.history.history['acc'])+1),model_history.history['acc'])\n",
        "    # axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    # axs[0].set_title('Model Accuracy')\n",
        "    # axs[0].set_ylabel('Accuracy')\n",
        "    # axs[0].set_xlabel('Epoch')\n",
        "    # axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    # axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs.plot(range(1,len(model_history.history.history['loss'])+1),model_history.history.history['loss'])\n",
        "    axs.plot(range(1,len(model_history.history.history['val_loss'])+1),model_history.history.history['val_loss'])\n",
        "    axs.set_title('Model Loss')\n",
        "    axs.set_ylabel('Loss')\n",
        "    axs.set_xlabel('Epoch')\n",
        "    axs.set_xticks(np.arange(1,len(model_history.history.history['loss'])+1),len(model_history.history.history['loss'])/10)\n",
        "    axs.legend(['train', 'val'], loc='best')\n",
        "    plt.show()\n",
        "# plot model history\n",
        "plot_model_history(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA7Vki4-QAQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1WB81PaN2ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgYCMe1chjKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}