{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5_PersonAttrubutes_vanilla14.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckgpeace/EIP4/blob/master/Assignment5/AssignmentOther_model/Assignment5_PersonAttrubutes_vanilla14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El-Dopn8pLpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "outputId": "00baa46c-d433-4c3d-ef31-90b249c8194e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  hvc_annotations.csv  \u001b[01;34mresized\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "outputId": "bce69a26-4616-4f23-c770-e8a52aee8e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout, GlobalAveragePooling2D, AveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, SeparableConv2D\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "outputId": "1db12860-3b98-42a0-a06b-b11310736036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>imagequality</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>carryingbag</th>\n",
              "      <th>footwear</th>\n",
              "      <th>emotion</th>\n",
              "      <th>bodypose</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>over-weight</td>\n",
              "      <td>None</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Angry/Serious</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Daily/Office/Work Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>Good</td>\n",
              "      <td>35-45</td>\n",
              "      <td>slightly-overweight</td>\n",
              "      <td>None</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender imagequality    age  ...        emotion        bodypose     image_path\n",
              "0    male      Average  35-45  ...        Neutral  Front-Frontish  resized/1.jpg\n",
              "1  female      Average  35-45  ...  Angry/Serious  Front-Frontish  resized/2.jpg\n",
              "2    male         Good  45-55  ...        Neutral  Front-Frontish  resized/3.jpg\n",
              "3    male         Good  45-55  ...        Neutral  Front-Frontish  resized/4.jpg\n",
              "4  female         Good  35-45  ...        Neutral  Front-Frontish  resized/5.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "outputId": "cecc407e-f798-487e-b859-f19c0aeaa9d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>image_path</th>\n",
              "      <td>resized/1.jpg</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_female</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_male</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Average</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Good</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_15-25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_25-35</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_35-45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_45-55</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_55+</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_over-weight</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_underweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_None</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Normal</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Happy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Sad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Back</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Side</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  0  ...              4\n",
              "image_path                            resized/1.jpg  ...  resized/5.jpg\n",
              "gender_female                                     0  ...              1\n",
              "gender_male                                       1  ...              0\n",
              "imagequality_Average                              1  ...              0\n",
              "imagequality_Bad                                  0  ...              0\n",
              "imagequality_Good                                 0  ...              1\n",
              "age_15-25                                         0  ...              0\n",
              "age_25-35                                         0  ...              0\n",
              "age_35-45                                         1  ...              1\n",
              "age_45-55                                         0  ...              0\n",
              "age_55+                                           0  ...              0\n",
              "weight_normal-healthy                             1  ...              0\n",
              "weight_over-weight                                0  ...              0\n",
              "weight_slightly-overweight                        0  ...              1\n",
              "weight_underweight                                0  ...              0\n",
              "carryingbag_Daily/Office/Work Bag                 0  ...              0\n",
              "carryingbag_Grocery/Home/Plastic Bag              1  ...              0\n",
              "carryingbag_None                                  0  ...              1\n",
              "footwear_CantSee                                  0  ...              1\n",
              "footwear_Fancy                                    0  ...              0\n",
              "footwear_Normal                                   1  ...              0\n",
              "emotion_Angry/Serious                             0  ...              0\n",
              "emotion_Happy                                     0  ...              0\n",
              "emotion_Neutral                                   1  ...              1\n",
              "emotion_Sad                                       0  ...              0\n",
              "bodypose_Back                                     0  ...              0\n",
              "bodypose_Front-Frontish                           1  ...              1\n",
              "bodypose_Side                                     0  ...              0\n",
              "\n",
              "[28 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=64, shuffle=True, augmentation = None):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.resize(cv2.imread(item[\"image_path\"]), (112,112)) for _, item in items.iterrows()])\n",
        "        #Image Normalization\n",
        "        if self.augmentation is not None:\n",
        "          self.augmentation.fit(image)\n",
        "          image = self.augmentation.flow(image,shuffle=False, batch_size = 64 ).next()\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "outputId": "f1ec6465-56ea-4523-dbd2-44937685a38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15, random_state = 404)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11537, 28), (2036, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "outputId": "95b04c3f-fc3a-4c24-9313-014c893dc19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>gender_female</th>\n",
              "      <th>gender_male</th>\n",
              "      <th>imagequality_Average</th>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <th>imagequality_Good</th>\n",
              "      <th>age_15-25</th>\n",
              "      <th>age_25-35</th>\n",
              "      <th>age_35-45</th>\n",
              "      <th>age_45-55</th>\n",
              "      <th>age_55+</th>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <th>weight_over-weight</th>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <th>weight_underweight</th>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <th>carryingbag_None</th>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <th>footwear_Normal</th>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <th>emotion_Happy</th>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <th>emotion_Sad</th>\n",
              "      <th>bodypose_Back</th>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <th>bodypose_Side</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10980</th>\n",
              "      <td>resized/10982.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11135</th>\n",
              "      <td>resized/11137.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1784</th>\n",
              "      <td>resized/1785.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7758</th>\n",
              "      <td>resized/7759.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4692</th>\n",
              "      <td>resized/4693.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              image_path  gender_female  ...  bodypose_Front-Frontish  bodypose_Side\n",
              "10980  resized/10982.jpg              0  ...                        1              0\n",
              "11135  resized/11137.jpg              0  ...                        0              1\n",
              "1784    resized/1785.jpg              0  ...                        1              0\n",
              "7758    resized/7759.jpg              0  ...                        0              1\n",
              "4692    resized/4693.jpg              0  ...                        1              0\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=64, shuffle=True, \n",
        "                                augmentation = ImageDataGenerator(horizontal_flip=True, \n",
        "                                                                  width_shift_range=0.2,\n",
        "                                                                  height_shift_range=0.2,\n",
        "                                                                  rotation_range=0,\n",
        "                                                                  zoom_range=0.2,\n",
        "                                                                  featurewise_center=True, featurewise_std_normalization=True))\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=64, shuffle=False, augmentation= ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "outputId": "62073a9c-06a0-4afe-e841-c570a76fa903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 5,\n",
              " 'bag': 3,\n",
              " 'emotion': 4,\n",
              " 'footwear': 3,\n",
              " 'gender': 2,\n",
              " 'image_quality': 3,\n",
              " 'pose': 3,\n",
              " 'weight': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03W8Pagg_Ppp",
        "colab_type": "code",
        "outputId": "6008a1ad-bdfa-49e3-bde5-350b49a6d736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "inp = Input(shape = (112,112,3))\n",
        "x = inp\n",
        "\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "### block 1\n",
        "\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Pooling \n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "# ================================================================\n",
        "\n",
        "### block\n",
        "\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), padding='valid')(x) \n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "\n",
        "# Pooling \n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "# ================================================================\n",
        "\n",
        "### block 2 \n",
        "x = SeparableConv2D(filters=256, kernel_size=(3, 3), padding='valid')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=256, kernel_size=(3, 3), padding='valid')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.05)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "\n",
        "# Pooling \n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=512, kernel_size=(3, 3), padding='valid')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.05)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = SeparableConv2D(filters=512, kernel_size=(3, 3), padding='valid')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.05)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "\n",
        "# Adding Dense layer\n",
        "def final(in_layer, num_units, class_name, output_name):\n",
        "  # Conv with class size\n",
        "  x = SeparableConv2D(filters=num_units[class_name], kernel_size=(1, 1), padding='valid')(in_layer)\n",
        "  # GAP\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Activation('softmax', name = output_name)(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "gender = final(in_layer = x, num_units = num_units,  class_name = \"gender\", output_name = \"gender_output\")\n",
        "image_quality = final(in_layer = x, num_units = num_units,  class_name = \"image_quality\", output_name = \"image_quality_output\")\n",
        "age = final(in_layer = x, num_units = num_units,  class_name = \"age\", output_name = \"age_output\")\n",
        "weight = final(in_layer = x, num_units = num_units,  class_name = \"weight\", output_name = \"weight_output\")\n",
        "bag = final(in_layer = x, num_units = num_units,  class_name = \"bag\", output_name = \"bag_output\")\n",
        "footwear = final(in_layer = x, num_units = num_units,  class_name = \"footwear\", output_name = \"footwear_output\")\n",
        "emotion = final(in_layer = x, num_units = num_units,  class_name = \"emotion\", output_name = \"emotion_output\")\n",
        "pose = final(in_layer = x, num_units = num_units,  class_name = \"pose\", output_name = \"pose_output\")\n",
        "\n",
        "model = Model(inputs = inp,outputs=[gender, image_quality, age, weight, bag, pose, footwear, emotion])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_20\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           (None, 112, 112, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_418 (Separable (None, 110, 110, 32) 155         input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 110, 110, 32) 0           separable_conv2d_418[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 110, 110, 32) 128         activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_419 (Separable (None, 108, 108, 64) 2400        batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 108, 108, 64) 0           separable_conv2d_419[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 108, 108, 64) 256         activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_420 (Separable (None, 106, 106, 64) 4736        batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 106, 106, 64) 0           separable_conv2d_420[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 106, 106, 64) 256         activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_421 (Separable (None, 104, 104, 64) 4736        batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 104, 104, 64) 0           separable_conv2d_421[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 104, 104, 64) 256         activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_64 (MaxPooling2D) (None, 52, 52, 64)   0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_422 (Separable (None, 50, 50, 128)  8896        max_pooling2d_64[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 50, 50, 128)  0           separable_conv2d_422[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 50, 50, 128)  512         activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_423 (Separable (None, 48, 48, 128)  17664       batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 48, 48, 128)  0           separable_conv2d_423[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 48, 48, 128)  512         activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_424 (Separable (None, 46, 46, 128)  17664       batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 46, 46, 128)  0           separable_conv2d_424[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 46, 46, 128)  512         activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_65 (MaxPooling2D) (None, 23, 23, 128)  0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_425 (Separable (None, 21, 21, 256)  34176       max_pooling2d_65[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 21, 21, 256)  0           separable_conv2d_425[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 21, 21, 256)  1024        activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_426 (Separable (None, 19, 19, 256)  68096       batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 19, 19, 256)  0           separable_conv2d_426[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 19, 19, 256)  0           activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 19, 19, 256)  1024        dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_66 (MaxPooling2D) (None, 9, 9, 256)    0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_427 (Separable (None, 7, 7, 512)    133888      max_pooling2d_66[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 7, 7, 512)    0           separable_conv2d_427[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 7, 7, 512)    0           activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 7, 7, 512)    2048        dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_428 (Separable (None, 5, 5, 512)    267264      batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 5, 5, 512)    0           separable_conv2d_428[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 5, 5, 512)    0           activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 5, 5, 512)    2048        dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_429 (Separable (None, 5, 5, 2)      1538        batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_430 (Separable (None, 5, 5, 3)      2051        batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_431 (Separable (None, 5, 5, 5)      3077        batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_432 (Separable (None, 5, 5, 4)      2564        batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_433 (Separable (None, 5, 5, 3)      2051        batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_436 (Separable (None, 5, 5, 3)      2051        batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_434 (Separable (None, 5, 5, 3)      2051        batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_435 (Separable (None, 5, 5, 4)      2564        batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_116 (G (None, 2)            0           separable_conv2d_429[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_117 (G (None, 3)            0           separable_conv2d_430[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_118 (G (None, 5)            0           separable_conv2d_431[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_119 (G (None, 4)            0           separable_conv2d_432[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_120 (G (None, 3)            0           separable_conv2d_433[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_123 (G (None, 3)            0           separable_conv2d_436[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_121 (G (None, 3)            0           separable_conv2d_434[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_122 (G (None, 4)            0           separable_conv2d_435[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Activation)      (None, 2)            0           global_average_pooling2d_116[0][0\n",
            "__________________________________________________________________________________________________\n",
            "image_quality_output (Activatio (None, 3)            0           global_average_pooling2d_117[0][0\n",
            "__________________________________________________________________________________________________\n",
            "age_output (Activation)         (None, 5)            0           global_average_pooling2d_118[0][0\n",
            "__________________________________________________________________________________________________\n",
            "weight_output (Activation)      (None, 4)            0           global_average_pooling2d_119[0][0\n",
            "__________________________________________________________________________________________________\n",
            "bag_output (Activation)         (None, 3)            0           global_average_pooling2d_120[0][0\n",
            "__________________________________________________________________________________________________\n",
            "pose_output (Activation)        (None, 3)            0           global_average_pooling2d_123[0][0\n",
            "__________________________________________________________________________________________________\n",
            "footwear_output (Activation)    (None, 3)            0           global_average_pooling2d_121[0][0\n",
            "__________________________________________________________________________________________________\n",
            "emotion_output (Activation)     (None, 4)            0           global_average_pooling2d_122[0][0\n",
            "==================================================================================================\n",
            "Total params: 586,198\n",
            "Trainable params: 581,910\n",
            "Non-trainable params: 4,288\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkqMc7GkN2sl",
        "colab_type": "code",
        "outputId": "9e94857b-c1ff-456e-b3c9-8bc7fc4e9c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from keras.utils import plot_model\n",
        "# plot_model(model)\n",
        "import time, psutil\n",
        "uptime = time.time() - psutil.boot_time()\n",
        "remain = 12*60*60 - uptime\n",
        "remain/(60*60)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.30710022535589"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1dcoduDN2pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = {\n",
        "\t\"gender_output\": \"categorical_crossentropy\",\n",
        "\t\"image_quality_output\": \"categorical_crossentropy\",\n",
        "\t\"age_output\": \"categorical_crossentropy\",\n",
        "\t\"weight_output\": \"categorical_crossentropy\",\n",
        "  \"bag_output\":  \"categorical_crossentropy\",\n",
        "  \"pose_output\": \"categorical_crossentropy\",\n",
        "  \"footwear_output\": \"categorical_crossentropy\",\n",
        "  \"emotion_output\": \"categorical_crossentropy\"\n",
        "}\n",
        "\n",
        "loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0, \"weight_output\" :1.0,  \"bag_output\": 1.0, \"pose_output\": 1.0,  \"footwear_output\": 1.0, \"emotion_output\": 1.0 }\n",
        "\n",
        "\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "decay_factor =  0.007\n",
        "def scheduler(epoch, lr):\n",
        "  return round(lr * 1/(1 + decay_factor * epoch), 10)\n",
        "\n",
        "opt = SGD(lr = 0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile( optimizer=opt, loss = losses, loss_weights=loss_weights, metrics=[\"accuracy\"])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyOyW5EOQAEJ",
        "colab_type": "code",
        "outputId": "0da58cf3-abb9-4e17-f148-2a6c0b26edf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# model_path = '/content/gdrive/VGG16_vanila_1.h5'\n",
        "# checkpoint = ModelCheckpoint(model_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max')\n",
        "\n",
        "import os\n",
        "# Checkpoint saving\n",
        "save_dir = os.path.join(os.getcwd(), \"/gdrive/My\\\\Drive/saved_models/\")\n",
        "model_name = \"model.{epoch:03d}.h5\"\n",
        "if not os.path.isdir(save_dir):\n",
        "  os.makedirs(save_dir)\n",
        "\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "\n",
        "checkpoint = ModelCheckpoint(model_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False)\n",
        "\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=11, verbose=1, mode='min')\n",
        "\n",
        "id2label = {1: 'B-LOC', 2: 'I-LOC'}\n",
        "f1score = F1Metrics(id2label)\n",
        "\n",
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    callbacks=[checkpoint, early, LearningRateScheduler(scheduler, verbose=1), f1score ]\n",
        "    # callbacks=[checkpoint, early, LearningRateScheduler(scheduler, verbose=1),TensorBoardColabCallback(tbc)]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.0099999998.\n",
            "180/180 [==============================] - 118s 654ms/step - loss: 7.9951 - gender_output_loss: 0.6681 - image_quality_output_loss: 0.9877 - age_output_loss: 1.4532 - weight_output_loss: 1.0357 - bag_output_loss: 0.9314 - pose_output_loss: 0.9389 - footwear_output_loss: 1.0136 - emotion_output_loss: 0.9666 - gender_output_acc: 0.5835 - image_quality_output_acc: 0.5489 - age_output_acc: 0.3955 - weight_output_acc: 0.6293 - bag_output_acc: 0.5638 - pose_output_acc: 0.6172 - footwear_output_acc: 0.4995 - emotion_output_acc: 0.7014 - val_loss: 8.2415 - val_gender_output_loss: 0.7063 - val_image_quality_output_loss: 1.1905 - val_age_output_loss: 1.4660 - val_weight_output_loss: 1.0078 - val_bag_output_loss: 1.0347 - val_pose_output_loss: 0.9848 - val_footwear_output_loss: 0.9747 - val_emotion_output_loss: 0.8767 - val_gender_output_acc: 0.6013 - val_image_quality_output_acc: 0.3221 - val_age_output_acc: 0.3916 - val_weight_output_acc: 0.6421 - val_bag_output_acc: 0.4007 - val_pose_output_acc: 0.5958 - val_footwear_output_acc: 0.5071 - val_emotion_output_acc: 0.7329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0099304864.\n",
            "180/180 [==============================] - 99s 552ms/step - loss: 7.6836 - gender_output_loss: 0.6431 - image_quality_output_loss: 0.9650 - age_output_loss: 1.4105 - weight_output_loss: 0.9773 - bag_output_loss: 0.8963 - pose_output_loss: 0.9145 - footwear_output_loss: 0.9676 - emotion_output_loss: 0.9094 - gender_output_acc: 0.6256 - image_quality_output_acc: 0.5530 - age_output_acc: 0.3999 - weight_output_acc: 0.6348 - bag_output_acc: 0.5693 - pose_output_acc: 0.6220 - footwear_output_acc: 0.5345 - emotion_output_acc: 0.7078 - val_loss: 8.0260 - val_gender_output_loss: 0.7187 - val_image_quality_output_loss: 1.0730 - val_age_output_loss: 1.4355 - val_weight_output_loss: 0.9792 - val_bag_output_loss: 0.9568 - val_pose_output_loss: 1.0122 - val_footwear_output_loss: 0.9680 - val_emotion_output_loss: 0.8826 - val_gender_output_acc: 0.6129 - val_image_quality_output_acc: 0.5277 - val_age_output_acc: 0.3896 - val_weight_output_acc: 0.6406 - val_bag_output_acc: 0.5459 - val_pose_output_acc: 0.5963 - val_footwear_output_acc: 0.5539 - val_emotion_output_acc: 0.7319\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0097933795.\n",
            "180/180 [==============================] - 99s 553ms/step - loss: 7.6009 - gender_output_loss: 0.6197 - image_quality_output_loss: 0.9532 - age_output_loss: 1.4038 - weight_output_loss: 0.9729 - bag_output_loss: 0.8864 - pose_output_loss: 0.9081 - footwear_output_loss: 0.9494 - emotion_output_loss: 0.9073 - gender_output_acc: 0.6530 - image_quality_output_acc: 0.5537 - age_output_acc: 0.3994 - weight_output_acc: 0.6345 - bag_output_acc: 0.5783 - pose_output_acc: 0.6217 - footwear_output_acc: 0.5466 - emotion_output_acc: 0.7078 - val_loss: 8.7600 - val_gender_output_loss: 0.9713 - val_image_quality_output_loss: 1.2282 - val_age_output_loss: 1.4909 - val_weight_output_loss: 1.0181 - val_bag_output_loss: 0.9457 - val_pose_output_loss: 1.1279 - val_footwear_output_loss: 1.0840 - val_emotion_output_loss: 0.8939 - val_gender_output_acc: 0.5862 - val_image_quality_output_acc: 0.4496 - val_age_output_acc: 0.3372 - val_weight_output_acc: 0.6033 - val_bag_output_acc: 0.5756 - val_pose_output_acc: 0.5958 - val_footwear_output_acc: 0.5343 - val_emotion_output_acc: 0.7329\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0095919484.\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 7.5200 - gender_output_loss: 0.5952 - image_quality_output_loss: 0.9468 - age_output_loss: 1.4003 - weight_output_loss: 0.9716 - bag_output_loss: 0.8751 - pose_output_loss: 0.8981 - footwear_output_loss: 0.9306 - emotion_output_loss: 0.9022 - gender_output_acc: 0.6763 - image_quality_output_acc: 0.5566 - age_output_acc: 0.4000 - weight_output_acc: 0.6350 - bag_output_acc: 0.5875 - pose_output_acc: 0.6217 - footwear_output_acc: 0.5639 - emotion_output_acc: 0.7080 - val_loss: 9.4007 - val_gender_output_loss: 1.0566 - val_image_quality_output_loss: 1.3931 - val_age_output_loss: 1.5693 - val_weight_output_loss: 0.9924 - val_bag_output_loss: 1.3437 - val_pose_output_loss: 0.9952 - val_footwear_output_loss: 1.0804 - val_emotion_output_loss: 0.9700 - val_gender_output_acc: 0.5000 - val_image_quality_output_acc: 0.3407 - val_age_output_acc: 0.3417 - val_weight_output_acc: 0.6421 - val_bag_output_acc: 0.3730 - val_pose_output_acc: 0.5958 - val_footwear_output_acc: 0.4496 - val_emotion_output_acc: 0.7112\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.009330689.\n",
            "180/180 [==============================] - 100s 554ms/step - loss: 7.4536 - gender_output_loss: 0.5711 - image_quality_output_loss: 0.9361 - age_output_loss: 1.3976 - weight_output_loss: 0.9713 - bag_output_loss: 0.8638 - pose_output_loss: 0.8876 - footwear_output_loss: 0.9237 - emotion_output_loss: 0.9025 - gender_output_acc: 0.6994 - image_quality_output_acc: 0.5560 - age_output_acc: 0.3993 - weight_output_acc: 0.6349 - bag_output_acc: 0.5983 - pose_output_acc: 0.6220 - footwear_output_acc: 0.5686 - emotion_output_acc: 0.7079 - val_loss: 8.4515 - val_gender_output_loss: 0.6127 - val_image_quality_output_loss: 1.4140 - val_age_output_loss: 1.4127 - val_weight_output_loss: 0.9753 - val_bag_output_loss: 0.8843 - val_pose_output_loss: 1.0758 - val_footwear_output_loss: 1.1633 - val_emotion_output_loss: 0.9135 - val_gender_output_acc: 0.6845 - val_image_quality_output_acc: 0.3342 - val_age_output_acc: 0.3836 - val_weight_output_acc: 0.6406 - val_bag_output_acc: 0.6094 - val_pose_output_acc: 0.5958 - val_footwear_output_acc: 0.4516 - val_emotion_output_acc: 0.7329\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0090151584.\n",
            "180/180 [==============================] - 101s 559ms/step - loss: 7.3829 - gender_output_loss: 0.5548 - image_quality_output_loss: 0.9308 - age_output_loss: 1.3948 - weight_output_loss: 0.9688 - bag_output_loss: 0.8595 - pose_output_loss: 0.8637 - footwear_output_loss: 0.9108 - emotion_output_loss: 0.8997 - gender_output_acc: 0.7127 - image_quality_output_acc: 0.5586 - age_output_acc: 0.4018 - weight_output_acc: 0.6353 - bag_output_acc: 0.6039 - pose_output_acc: 0.6249 - footwear_output_acc: 0.5753 - emotion_output_acc: 0.7082 - val_loss: 7.6845 - val_gender_output_loss: 0.5562 - val_image_quality_output_loss: 1.1362 - val_age_output_loss: 1.4240 - val_weight_output_loss: 0.9732 - val_bag_output_loss: 0.8688 - val_pose_output_loss: 0.8843 - val_footwear_output_loss: 0.9745 - val_emotion_output_loss: 0.8674 - val_gender_output_acc: 0.7167 - val_image_quality_output_acc: 0.4748 - val_age_output_acc: 0.3589 - val_weight_output_acc: 0.6316 - val_bag_output_acc: 0.6149 - val_pose_output_acc: 0.6134 - val_footwear_output_acc: 0.5489 - val_emotion_output_acc: 0.7339\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0086517838.\n",
            "180/180 [==============================] - 99s 551ms/step - loss: 7.3100 - gender_output_loss: 0.5388 - image_quality_output_loss: 0.9279 - age_output_loss: 1.3928 - weight_output_loss: 0.9685 - bag_output_loss: 0.8579 - pose_output_loss: 0.8236 - footwear_output_loss: 0.9040 - emotion_output_loss: 0.8966 - gender_output_acc: 0.7213 - image_quality_output_acc: 0.5616 - age_output_acc: 0.4003 - weight_output_acc: 0.6345 - bag_output_acc: 0.6006 - pose_output_acc: 0.6381 - footwear_output_acc: 0.5794 - emotion_output_acc: 0.7080 - val_loss: 8.8993 - val_gender_output_loss: 1.1497 - val_image_quality_output_loss: 1.1182 - val_age_output_loss: 1.4459 - val_weight_output_loss: 0.9982 - val_bag_output_loss: 0.9293 - val_pose_output_loss: 1.2951 - val_footwear_output_loss: 1.0279 - val_emotion_output_loss: 0.9348 - val_gender_output_acc: 0.6205 - val_image_quality_output_acc: 0.5252 - val_age_output_acc: 0.3609 - val_weight_output_acc: 0.6361 - val_bag_output_acc: 0.6048 - val_pose_output_acc: 0.6003 - val_footwear_output_acc: 0.5706 - val_emotion_output_acc: 0.7182\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0082476489.\n",
            "\n",
            "180/180 [==============================] - 101s 559ms/step - loss: 7.2163 - gender_output_loss: 0.5217 - image_quality_output_loss: 0.9216 - age_output_loss: 1.3878 - weight_output_loss: 0.9676 - bag_output_loss: 0.8493 - pose_output_loss: 0.7779 - footwear_output_loss: 0.8956 - emotion_output_loss: 0.8947 - gender_output_acc: 0.7378 - image_quality_output_acc: 0.5600 - age_output_acc: 0.4036 - weight_output_acc: 0.6341 - bag_output_acc: 0.6102 - pose_output_acc: 0.6589 - footwear_output_acc: 0.5839 - emotion_output_acc: 0.7076 - val_loss: 9.8527 - val_gender_output_loss: 1.2740 - val_image_quality_output_loss: 1.4430 - val_age_output_loss: 1.5133 - val_weight_output_loss: 1.0197 - val_bag_output_loss: 1.0000 - val_pose_output_loss: 1.2928 - val_footwear_output_loss: 1.2826 - val_emotion_output_loss: 1.0272 - val_gender_output_acc: 0.5983 - val_image_quality_output_acc: 0.3241 - val_age_output_acc: 0.3185 - val_weight_output_acc: 0.6053 - val_bag_output_acc: 0.5887 - val_pose_output_acc: 0.6018 - val_footwear_output_acc: 0.5060 - val_emotion_output_acc: 0.6356\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.007810274.\n",
            "180/180 [==============================] - 100s 553ms/step - loss: 7.1524 - gender_output_loss: 0.5090 - image_quality_output_loss: 0.9186 - age_output_loss: 1.3881 - weight_output_loss: 0.9651 - bag_output_loss: 0.8442 - pose_output_loss: 0.7411 - footwear_output_loss: 0.8942 - emotion_output_loss: 0.8922 - gender_output_acc: 0.7489 - image_quality_output_acc: 0.5640 - age_output_acc: 0.4043 - weight_output_acc: 0.6352 - bag_output_acc: 0.6162 - pose_output_acc: 0.6809 - footwear_output_acc: 0.5849 - emotion_output_acc: 0.7076 - val_loss: 7.3036 - val_gender_output_loss: 0.4892 - val_image_quality_output_loss: 1.0732 - val_age_output_loss: 1.4075 - val_weight_output_loss: 0.9565 - val_bag_output_loss: 0.8897 - val_pose_output_loss: 0.7496 - val_footwear_output_loss: 0.8928 - val_emotion_output_loss: 0.8451 - val_gender_output_acc: 0.7530 - val_image_quality_output_acc: 0.4632 - val_age_output_acc: 0.3962 - val_weight_output_acc: 0.6421 - val_bag_output_acc: 0.5847 - val_pose_output_acc: 0.6739 - val_footwear_output_acc: 0.5857 - val_emotion_output_acc: 0.7334\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0073473887.\n",
            "180/180 [==============================] - 100s 554ms/step - loss: 7.0709 - gender_output_loss: 0.4849 - image_quality_output_loss: 0.9148 - age_output_loss: 1.3819 - weight_output_loss: 0.9631 - bag_output_loss: 0.8407 - pose_output_loss: 0.7091 - footwear_output_loss: 0.8852 - emotion_output_loss: 0.8911 - gender_output_acc: 0.7607 - image_quality_output_acc: 0.5645 - age_output_acc: 0.4075 - weight_output_acc: 0.6346 - bag_output_acc: 0.6195 - pose_output_acc: 0.6942 - footwear_output_acc: 0.5894 - emotion_output_acc: 0.7076 - val_loss: 7.8549 - val_gender_output_loss: 0.7063 - val_image_quality_output_loss: 1.2485 - val_age_output_loss: 1.4036 - val_weight_output_loss: 0.9584 - val_bag_output_loss: 0.8940 - val_pose_output_loss: 0.7355 - val_footwear_output_loss: 1.0444 - val_emotion_output_loss: 0.8641 - val_gender_output_acc: 0.7147 - val_image_quality_output_acc: 0.4093 - val_age_output_acc: 0.3881 - val_weight_output_acc: 0.6245 - val_bag_output_acc: 0.6074 - val_pose_output_acc: 0.6789 - val_footwear_output_acc: 0.5373 - val_emotion_output_acc: 0.7329\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0073473887.\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0068667184.\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 7.0274 - gender_output_loss: 0.4805 - image_quality_output_loss: 0.9137 - age_output_loss: 1.3758 - weight_output_loss: 0.9619 - bag_output_loss: 0.8359 - pose_output_loss: 0.6875 - footwear_output_loss: 0.8837 - emotion_output_loss: 0.8885 - gender_output_acc: 0.7630 - image_quality_output_acc: 0.5670 - age_output_acc: 0.4065 - weight_output_acc: 0.6351 - bag_output_acc: 0.6267 - pose_output_acc: 0.7063 - footwear_output_acc: 0.5908 - emotion_output_acc: 0.7077 - val_loss: 8.3301 - val_gender_output_loss: 0.4923 - val_image_quality_output_loss: 1.3640 - val_age_output_loss: 1.3971 - val_weight_output_loss: 0.9487 - val_bag_output_loss: 1.2643 - val_pose_output_loss: 0.9670 - val_footwear_output_loss: 0.9511 - val_emotion_output_loss: 0.9456 - val_gender_output_acc: 0.7697 - val_image_quality_output_acc: 0.3372 - val_age_output_acc: 0.3836 - val_weight_output_acc: 0.6406 - val_bag_output_acc: 0.4496 - val_pose_output_acc: 0.6583 - val_footwear_output_acc: 0.5126 - val_emotion_output_acc: 0.6930\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0063757829.\n",
            "180/180 [==============================] - 100s 557ms/step - loss: 6.9723 - gender_output_loss: 0.4645 - image_quality_output_loss: 0.9088 - age_output_loss: 1.3765 - weight_output_loss: 0.9580 - bag_output_loss: 0.8292 - pose_output_loss: 0.6699 - footwear_output_loss: 0.8805 - emotion_output_loss: 0.8849 - gender_output_acc: 0.7802 - image_quality_output_acc: 0.5647 - age_output_acc: 0.4056 - weight_output_acc: 0.6354 - bag_output_acc: 0.6303 - pose_output_acc: 0.7188 - footwear_output_acc: 0.5917 - emotion_output_acc: 0.7081 - val_loss: 7.2468 - val_gender_output_loss: 0.4968 - val_image_quality_output_loss: 1.1281 - val_age_output_loss: 1.3863 - val_weight_output_loss: 0.9484 - val_bag_output_loss: 0.8282 - val_pose_output_loss: 0.6737 - val_footwear_output_loss: 0.9099 - val_emotion_output_loss: 0.8753 - val_gender_output_acc: 0.7591 - val_image_quality_output_acc: 0.4254 - val_age_output_acc: 0.4032 - val_weight_output_acc: 0.6426 - val_bag_output_acc: 0.6426 - val_pose_output_acc: 0.7127 - val_footwear_output_acc: 0.5595 - val_emotion_output_acc: 0.7329\n",
            "180/180 [==============================]Epoch 13/100\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0058817187.\n",
            "179/180 [============================>.] - ETA: 0s - loss: 6.9189 - gender_output_loss: 0.4554 - image_quality_output_loss: 0.9082 - age_output_loss: 1.3729 - weight_output_loss: 0.9559 - bag_output_loss: 0.8251 - pose_output_loss: 0.6501 - footwear_output_loss: 0.8674 - emotion_output_loss: 0.8840 - gender_output_acc: 0.7846 - image_quality_output_acc: 0.5692 - age_output_acc: 0.4077 - weight_output_acc: 0.6348 - bag_output_acc: 0.6323 - pose_output_acc: 0.7293 - footwear_output_acc: 0.6013 - emotion_output_acc: 0.7078Epoch 13/100\n",
            "180/180 [==============================] - 100s 555ms/step - loss: 6.9181 - gender_output_loss: 0.4555 - image_quality_output_loss: 0.9087 - age_output_loss: 1.3729 - weight_output_loss: 0.9555 - bag_output_loss: 0.8246 - pose_output_loss: 0.6497 - footwear_output_loss: 0.8669 - emotion_output_loss: 0.8843 - gender_output_acc: 0.7840 - image_quality_output_acc: 0.5691 - age_output_acc: 0.4079 - weight_output_acc: 0.6352 - bag_output_acc: 0.6327 - pose_output_acc: 0.7293 - footwear_output_acc: 0.6019 - emotion_output_acc: 0.7076 - val_loss: 7.5290 - val_gender_output_loss: 0.5090 - val_image_quality_output_loss: 1.2069 - val_age_output_loss: 1.4338 - val_weight_output_loss: 0.9520 - val_bag_output_loss: 0.8594 - val_pose_output_loss: 0.6839 - val_footwear_output_loss: 1.0393 - val_emotion_output_loss: 0.8447 - val_gender_output_acc: 0.7646 - val_image_quality_output_acc: 0.3584 - val_age_output_acc: 0.4002 - val_weight_output_acc: 0.6421 - val_bag_output_acc: 0.6190 - val_pose_output_acc: 0.7137 - val_footwear_output_acc: 0.4955 - val_emotion_output_acc: 0.7329\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0053911263.\n",
            "180/180 [==============================] - 100s 554ms/step - loss: 6.8583 - gender_output_loss: 0.4402 - image_quality_output_loss: 0.9038 - age_output_loss: 1.3695 - weight_output_loss: 0.9530 - bag_output_loss: 0.8195 - pose_output_loss: 0.6256 - footwear_output_loss: 0.8648 - emotion_output_loss: 0.8819 - gender_output_acc: 0.7938 - image_quality_output_acc: 0.5684 - age_output_acc: 0.4091 - weight_output_acc: 0.6369 - bag_output_acc: 0.6332 - pose_output_acc: 0.7389 - footwear_output_acc: 0.6007 - emotion_output_acc: 0.7079 - val_loss: 7.5331 - val_gender_output_loss: 0.5702 - val_image_quality_output_loss: 1.1834 - val_age_output_loss: 1.3859 - val_weight_output_loss: 0.9664 - val_bag_output_loss: 0.8377 - val_pose_output_loss: 0.6761 - val_footwear_output_loss: 1.0565 - val_emotion_output_loss: 0.8570 - val_gender_output_acc: 0.7485 - val_image_quality_output_acc: 0.3997 - val_age_output_acc: 0.3921 - val_weight_output_acc: 0.6205 - val_bag_output_acc: 0.6396 - val_pose_output_acc: 0.7303 - val_footwear_output_acc: 0.5272 - val_emotion_output_acc: 0.7278\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0049099513.\n",
            "180/180 [==============================] - 100s 557ms/step - loss: 6.8442 - gender_output_loss: 0.4386 - image_quality_output_loss: 0.9032 - age_output_loss: 1.3677 - weight_output_loss: 0.9505 - bag_output_loss: 0.8146 - pose_output_loss: 0.6214 - footwear_output_loss: 0.8660 - emotion_output_loss: 0.8823 - gender_output_acc: 0.7930 - image_quality_output_acc: 0.5713 - age_output_acc: 0.4096 - weight_output_acc: 0.6380 - bag_output_acc: 0.6440 - pose_output_acc: 0.7413 - footwear_output_acc: 0.6014 - emotion_output_acc: 0.7079 - val_loss: 7.3759 - val_gender_output_loss: 0.4328 - val_image_quality_output_loss: 1.2422 - val_age_output_loss: 1.3931 - val_weight_output_loss: 0.9396 - val_bag_output_loss: 0.8750 - val_pose_output_loss: 0.6083 - val_footwear_output_loss: 1.0242 - val_emotion_output_loss: 0.8607 - val_gender_output_acc: 0.7923 - val_image_quality_output_acc: 0.3569 - val_age_output_acc: 0.3977 - val_weight_output_acc: 0.6411 - val_bag_output_acc: 0.5973 - val_pose_output_acc: 0.7409 - val_footwear_output_acc: 0.4950 - val_emotion_output_acc: 0.7314\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0044433948.\n",
            "180/180 [==============================] - 99s 553ms/step - loss: 6.7942 - gender_output_loss: 0.4296 - image_quality_output_loss: 0.8999 - age_output_loss: 1.3623 - weight_output_loss: 0.9426 - bag_output_loss: 0.8119 - pose_output_loss: 0.6083 - footwear_output_loss: 0.8579 - emotion_output_loss: 0.8817 - gender_output_acc: 0.8002 - image_quality_output_acc: 0.5718 - age_output_acc: 0.4089 - weight_output_acc: 0.6405 - bag_output_acc: 0.6432 - pose_output_acc: 0.7502 - footwear_output_acc: 0.6026 - emotion_output_acc: 0.7076 - val_loss: 7.3676 - val_gender_output_loss: 0.4541 - val_image_quality_output_loss: 1.1131 - val_age_output_loss: 1.3992 - val_weight_output_loss: 0.9849 - val_bag_output_loss: 0.8418 - val_pose_output_loss: 0.5872 - val_footwear_output_loss: 1.1353 - val_emotion_output_loss: 0.8521 - val_gender_output_acc: 0.8019 - val_image_quality_output_acc: 0.4204 - val_age_output_acc: 0.3851 - val_weight_output_acc: 0.6013 - val_bag_output_acc: 0.6401 - val_pose_output_acc: 0.7631 - val_footwear_output_acc: 0.4677 - val_emotion_output_acc: 0.7298\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0039958588.\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 6.7458 - gender_output_loss: 0.4150 - image_quality_output_loss: 0.8985 - age_output_loss: 1.3579 - weight_output_loss: 0.9424 - bag_output_loss: 0.8078 - pose_output_loss: 0.5945 - footwear_output_loss: 0.8513 - emotion_output_loss: 0.8785 - gender_output_acc: 0.8093 - image_quality_output_acc: 0.5724 - age_output_acc: 0.4091 - weight_output_acc: 0.6390 - bag_output_acc: 0.6446 - pose_output_acc: 0.7576 - footwear_output_acc: 0.6103 - emotion_output_acc: 0.7076 - val_loss: 6.9609 - val_gender_output_loss: 0.4301 - val_image_quality_output_loss: 1.0070 - val_age_output_loss: 1.3785 - val_weight_output_loss: 0.9390 - val_bag_output_loss: 0.8420 - val_pose_output_loss: 0.5777 - val_footwear_output_loss: 0.9398 - val_emotion_output_loss: 0.8468 - val_gender_output_acc: 0.8135 - val_image_quality_output_acc: 0.5106 - val_age_output_acc: 0.3962 - val_weight_output_acc: 0.6396 - val_bag_output_acc: 0.6295 - val_pose_output_acc: 0.7676 - val_footwear_output_acc: 0.5670 - val_emotion_output_acc: 0.7288\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0035709192.\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 6.7257 - gender_output_loss: 0.4104 - image_quality_output_loss: 0.8954 - age_output_loss: 1.3605 - weight_output_loss: 0.9377 - bag_output_loss: 0.8053 - pose_output_loss: 0.5931 - footwear_output_loss: 0.8454 - emotion_output_loss: 0.8779 - gender_output_acc: 0.8131 - image_quality_output_acc: 0.5738 - age_output_acc: 0.4070 - weight_output_acc: 0.6385 - bag_output_acc: 0.6485 - pose_output_acc: 0.7576 - footwear_output_acc: 0.6105 - emotion_output_acc: 0.7080 - val_loss: 6.8707 - val_gender_output_loss: 0.3580 - val_image_quality_output_loss: 1.0715 - val_age_output_loss: 1.3697 - val_weight_output_loss: 0.9335 - val_bag_output_loss: 0.8163 - val_pose_output_loss: 0.5591 - val_footwear_output_loss: 0.9144 - val_emotion_output_loss: 0.8482 - val_gender_output_acc: 0.8377 - val_image_quality_output_acc: 0.4446 - val_age_output_acc: 0.4017 - val_weight_output_acc: 0.6376 - val_bag_output_acc: 0.6578 - val_pose_output_acc: 0.7681 - val_footwear_output_acc: 0.5635 - val_emotion_output_acc: 0.7319\n",
            "Epoch 19/100\n",
            "\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0031713314.\n",
            "179/180 [============================>.] - ETA: 0s - loss: 6.6992 - gender_output_loss: 0.4056 - image_quality_output_loss: 0.8946 - age_output_loss: 1.3563 - weight_output_loss: 0.9378 - bag_output_loss: 0.8039 - pose_output_loss: 0.5804 - footwear_output_loss: 0.8435 - emotion_output_loss: 0.8771 - gender_output_acc: 0.8146 - image_quality_output_acc: 0.5725 - age_output_acc: 0.4117 - weight_output_acc: 0.6393 - bag_output_acc: 0.6505 - pose_output_acc: 0.7631 - footwear_output_acc: 0.6109 - emotion_output_acc: 0.7079\n",
            "\n",
            "180/180 [==============================] - 101s 560ms/step - loss: 6.6983 - gender_output_loss: 0.4063 - image_quality_output_loss: 0.8946 - age_output_loss: 1.3557 - weight_output_loss: 0.9369 - bag_output_loss: 0.8045 - pose_output_loss: 0.5798 - footwear_output_loss: 0.8435 - emotion_output_loss: 0.8771 - gender_output_acc: 0.8141 - image_quality_output_acc: 0.5722 - age_output_acc: 0.4122 - weight_output_acc: 0.6399 - bag_output_acc: 0.6500 - pose_output_acc: 0.7634 - footwear_output_acc: 0.6110 - emotion_output_acc: 0.7079 - val_loss: 6.8718 - val_gender_output_loss: 0.3619 - val_image_quality_output_loss: 1.1091 - val_age_output_loss: 1.3690 - val_weight_output_loss: 0.9210 - val_bag_output_loss: 0.8162 - val_pose_output_loss: 0.5605 - val_footwear_output_loss: 0.8866 - val_emotion_output_loss: 0.8475 - val_gender_output_acc: 0.8372 - val_image_quality_output_acc: 0.4405 - val_age_output_acc: 0.4057 - val_weight_output_acc: 0.6421 - val_bag_output_acc: 0.6568 - val_pose_output_acc: 0.7772 - val_footwear_output_acc: 0.5751 - val_emotion_output_acc: 0.7314\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0027990569.\n",
            "180/180 [==============================] - 100s 553ms/step - loss: 6.6608 - gender_output_loss: 0.3957 - image_quality_output_loss: 0.8950 - age_output_loss: 1.3538 - weight_output_loss: 0.9357 - bag_output_loss: 0.7960 - pose_output_loss: 0.5674 - footwear_output_loss: 0.8399 - emotion_output_loss: 0.8775 - gender_output_acc: 0.8185 - image_quality_output_acc: 0.5722 - age_output_acc: 0.4108 - weight_output_acc: 0.6408 - bag_output_acc: 0.6549 - pose_output_acc: 0.7693 - footwear_output_acc: 0.6183 - emotion_output_acc: 0.7072 - val_loss: 7.1127 - val_gender_output_loss: 0.4498 - val_image_quality_output_loss: 1.1726 - val_age_output_loss: 1.3779 - val_weight_output_loss: 0.9229 - val_bag_output_loss: 0.8237 - val_pose_output_loss: 0.5912 - val_footwear_output_loss: 0.9153 - val_emotion_output_loss: 0.8593 - val_gender_output_acc: 0.8014 - val_image_quality_output_acc: 0.3967 - val_age_output_acc: 0.4057 - val_weight_output_acc: 0.6411 - val_bag_output_acc: 0.6442 - val_pose_output_acc: 0.7681 - val_footwear_output_acc: 0.5459 - val_emotion_output_acc: 0.7238\n",
            "Epoch 21/100\n",
            "180/180 [==============================]\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0024553131.\n",
            "180/180 [==============================] - 101s 560ms/step - loss: 6.6250 - gender_output_loss: 0.3895 - image_quality_output_loss: 0.8944 - age_output_loss: 1.3504 - weight_output_loss: 0.9305 - bag_output_loss: 0.7946 - pose_output_loss: 0.5548 - footwear_output_loss: 0.8357 - emotion_output_loss: 0.8750 - gender_output_acc: 0.8253 - image_quality_output_acc: 0.5765 - age_output_acc: 0.4152 - weight_output_acc: 0.6436 - bag_output_acc: 0.6539 - pose_output_acc: 0.7739 - footwear_output_acc: 0.6185 - emotion_output_acc: 0.7078 - val_loss: 6.7615 - val_gender_output_loss: 0.3996 - val_image_quality_output_loss: 0.9824 - val_age_output_loss: 1.3751 - val_weight_output_loss: 0.9239 - val_bag_output_loss: 0.8272 - val_pose_output_loss: 0.5517 - val_footwear_output_loss: 0.8597 - val_emotion_output_loss: 0.8419 - val_gender_output_acc: 0.8266 - val_image_quality_output_acc: 0.5363 - val_age_output_acc: 0.4022 - val_weight_output_acc: 0.6472 - val_bag_output_acc: 0.6452 - val_pose_output_acc: 0.7873 - val_footwear_output_acc: 0.6119 - val_emotion_output_acc: 0.7324\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0021406391.\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 6.6147 - gender_output_loss: 0.3851 - image_quality_output_loss: 0.8904 - age_output_loss: 1.3514 - weight_output_loss: 0.9324 - bag_output_loss: 0.7936 - pose_output_loss: 0.5559 - footwear_output_loss: 0.8301 - emotion_output_loss: 0.8757 - gender_output_acc: 0.8280 - image_quality_output_acc: 0.5725 - age_output_acc: 0.4129 - weight_output_acc: 0.6442 - bag_output_acc: 0.6552 - pose_output_acc: 0.7774 - footwear_output_acc: 0.6216 - emotion_output_acc: 0.7078 - val_loss: 6.8533 - val_gender_output_loss: 0.3886 - val_image_quality_output_loss: 1.0301 - val_age_output_loss: 1.3668 - val_weight_output_loss: 0.9232 - val_bag_output_loss: 0.8167 - val_pose_output_loss: 0.5570 - val_footwear_output_loss: 0.9278 - val_emotion_output_loss: 0.8430 - val_gender_output_acc: 0.8281 - val_image_quality_output_acc: 0.4909 - val_age_output_acc: 0.3997 - val_weight_output_acc: 0.6366 - val_bag_output_acc: 0.6527 - val_pose_output_acc: 0.7812 - val_footwear_output_acc: 0.5549 - val_emotion_output_acc: 0.7303\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0018549732.\n",
            "179/180 [============================>.] - ETA: 0s - loss: 6.5634 - gender_output_loss: 0.3751 - image_quality_output_loss: 0.8826 - age_output_loss: 1.3446 - weight_output_loss: 0.9267 - bag_output_loss: 0.7899 - pose_output_loss: 0.5401 - footwear_output_loss: 0.8316 - emotion_output_loss: 0.8727 - gender_output_acc: 0.8336 - image_quality_output_acc: 0.5805 - age_output_acc: 0.4178 - weight_output_acc: 0.6422 - bag_output_acc: 0.6561 - pose_output_acc: 0.7826 - footwear_output_acc: 0.6163 - emotion_output_acc: 0.7078\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 6.5657 - gender_output_loss: 0.3751 - image_quality_output_loss: 0.8834 - age_output_loss: 1.3450 - weight_output_loss: 0.9273 - bag_output_loss: 0.7899 - pose_output_loss: 0.5411 - footwear_output_loss: 0.8311 - emotion_output_loss: 0.8729 - gender_output_acc: 0.8332 - image_quality_output_acc: 0.5799 - age_output_acc: 0.4174 - weight_output_acc: 0.6419 - bag_output_acc: 0.6563 - pose_output_acc: 0.7821 - footwear_output_acc: 0.6166 - emotion_output_acc: 0.7077 - val_loss: 6.8015 - val_gender_output_loss: 0.3807 - val_image_quality_output_loss: 1.0285 - val_age_output_loss: 1.3692 - val_weight_output_loss: 0.9408 - val_bag_output_loss: 0.8088 - val_pose_output_loss: 0.5448 - val_footwear_output_loss: 0.8850 - val_emotion_output_loss: 0.8438 - val_gender_output_acc: 0.8236 - val_image_quality_output_acc: 0.5015 - val_age_output_acc: 0.4093 - val_weight_output_acc: 0.6235 - val_bag_output_acc: 0.6603 - val_pose_output_acc: 0.7853 - val_footwear_output_acc: 0.5801 - val_emotion_output_acc: 0.7329\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0015977374.\n",
            "179/180 [============================>.] - ETA: 0s - loss: 6.5405 - gender_output_loss: 0.3739 - image_quality_output_loss: 0.8853 - age_output_loss: 1.3433 - weight_output_loss: 0.9269 - bag_output_loss: 0.7794 - pose_output_loss: 0.5287 - footwear_output_loss: 0.8296 - emotion_output_loss: 0.8734 - gender_output_acc: 0.8346 - image_quality_output_acc: 0.5794 - age_output_acc: 0.4195 - weight_output_acc: 0.6419 - bag_output_acc: 0.6658 - pose_output_acc: 0.7882 - footwear_output_acc: 0.6192 - emotion_output_acc: 0.7073Epoch 24/100\n",
            "180/180 [==============================] - 100s 557ms/step - loss: 6.5392 - gender_output_loss: 0.3734 - image_quality_output_loss: 0.8853 - age_output_loss: 1.3434 - weight_output_loss: 0.9276 - bag_output_loss: 0.7788 - pose_output_loss: 0.5287 - footwear_output_loss: 0.8293 - emotion_output_loss: 0.8728 - gender_output_acc: 0.8347 - image_quality_output_acc: 0.5787 - age_output_acc: 0.4192 - weight_output_acc: 0.6418 - bag_output_acc: 0.6659 - pose_output_acc: 0.7880 - footwear_output_acc: 0.6191 - emotion_output_acc: 0.7078 - val_loss: 6.6593 - val_gender_output_loss: 0.3548 - val_image_quality_output_loss: 0.9960 - val_age_output_loss: 1.3583 - val_weight_output_loss: 0.9130 - val_bag_output_loss: 0.8036 - val_pose_output_loss: 0.5457 - val_footwear_output_loss: 0.8484 - val_emotion_output_loss: 0.8395 - val_gender_output_acc: 0.8458 - val_image_quality_output_acc: 0.5237 - val_age_output_acc: 0.4017 - val_weight_output_acc: 0.6447 - val_bag_output_acc: 0.6678 - val_pose_output_acc: 0.7868 - val_footwear_output_acc: 0.6109 - val_emotion_output_acc: 0.7314\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0013679259.\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 6.5262 - gender_output_loss: 0.3670 - image_quality_output_loss: 0.8829 - age_output_loss: 1.3416 - weight_output_loss: 0.9263 - bag_output_loss: 0.7829 - pose_output_loss: 0.5337 - footwear_output_loss: 0.8217 - emotion_output_loss: 0.8702 - gender_output_acc: 0.8339 - image_quality_output_acc: 0.5813 - age_output_acc: 0.4204 - weight_output_acc: 0.6408 - bag_output_acc: 0.6608 - pose_output_acc: 0.7849 - footwear_output_acc: 0.6258 - emotion_output_acc: 0.7074 - val_loss: 6.7377 - val_gender_output_loss: 0.3725 - val_image_quality_output_loss: 1.0252 - val_age_output_loss: 1.3642 - val_weight_output_loss: 0.9211 - val_bag_output_loss: 0.8037 - val_pose_output_loss: 0.5388 - val_footwear_output_loss: 0.8583 - val_emotion_output_loss: 0.8539 - val_gender_output_acc: 0.8412 - val_image_quality_output_acc: 0.4859 - val_age_output_acc: 0.4083 - val_weight_output_acc: 0.6396 - val_bag_output_acc: 0.6623 - val_pose_output_acc: 0.7933 - val_footwear_output_acc: 0.5897 - val_emotion_output_acc: 0.7283\n",
            "Epoch 26/100\n",
            "\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0011641923.\n",
            "180/180 [==============================] - 99s 553ms/step - loss: 6.5279 - gender_output_loss: 0.3682 - image_quality_output_loss: 0.8843 - age_output_loss: 1.3415 - weight_output_loss: 0.9232 - bag_output_loss: 0.7815 - pose_output_loss: 0.5310 - footwear_output_loss: 0.8276 - emotion_output_loss: 0.8705 - gender_output_acc: 0.8353 - image_quality_output_acc: 0.5837 - age_output_acc: 0.4196 - weight_output_acc: 0.6442 - bag_output_acc: 0.6642 - pose_output_acc: 0.7885 - footwear_output_acc: 0.6179 - emotion_output_acc: 0.7076 - val_loss: 6.8647 - val_gender_output_loss: 0.3650 - val_image_quality_output_loss: 1.0957 - val_age_output_loss: 1.3628 - val_weight_output_loss: 0.9350 - val_bag_output_loss: 0.8121 - val_pose_output_loss: 0.5352 - val_footwear_output_loss: 0.9064 - val_emotion_output_loss: 0.8525 - val_gender_output_acc: 0.8443 - val_image_quality_output_acc: 0.4410 - val_age_output_acc: 0.4189 - val_weight_output_acc: 0.6245 - val_bag_output_acc: 0.6492 - val_pose_output_acc: 0.7903 - val_footwear_output_acc: 0.5650 - val_emotion_output_acc: 0.7248\n",
            "\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0009849343.\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 6.4895 - gender_output_loss: 0.3614 - image_quality_output_loss: 0.8819 - age_output_loss: 1.3364 - weight_output_loss: 0.9190 - bag_output_loss: 0.7773 - pose_output_loss: 0.5190 - footwear_output_loss: 0.8235 - emotion_output_loss: 0.8710 - gender_output_acc: 0.8404 - image_quality_output_acc: 0.5805 - age_output_acc: 0.4208 - weight_output_acc: 0.6470 - bag_output_acc: 0.6641 - pose_output_acc: 0.7964 - footwear_output_acc: 0.6259 - emotion_output_acc: 0.7078 - val_loss: 6.7563 - val_gender_output_loss: 0.3678 - val_image_quality_output_loss: 1.0097 - val_age_output_loss: 1.3675 - val_weight_output_loss: 0.9188 - val_bag_output_loss: 0.8067 - val_pose_output_loss: 0.5245 - val_footwear_output_loss: 0.9214 - val_emotion_output_loss: 0.8399 - val_gender_output_acc: 0.8377 - val_image_quality_output_acc: 0.5136 - val_age_output_acc: 0.4113 - val_weight_output_acc: 0.6452 - val_bag_output_acc: 0.6613 - val_pose_output_acc: 0.7959 - val_footwear_output_acc: 0.5696 - val_emotion_output_acc: 0.7298\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.000828372.\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 6.4932 - gender_output_loss: 0.3549 - image_quality_output_loss: 0.8839 - age_output_loss: 1.3387 - weight_output_loss: 0.9167 - bag_output_loss: 0.7789 - pose_output_loss: 0.5293 - footwear_output_loss: 0.8204 - emotion_output_loss: 0.8704 - gender_output_acc: 0.8428 - image_quality_output_acc: 0.5786 - age_output_acc: 0.4216 - weight_output_acc: 0.6440 - bag_output_acc: 0.6641 - pose_output_acc: 0.7907 - footwear_output_acc: 0.6234 - emotion_output_acc: 0.7081 - val_loss: 6.8010 - val_gender_output_loss: 0.3910 - val_image_quality_output_loss: 1.0665 - val_age_output_loss: 1.3651 - val_weight_output_loss: 0.9102 - val_bag_output_loss: 0.8271 - val_pose_output_loss: 0.5214 - val_footwear_output_loss: 0.8727 - val_emotion_output_loss: 0.8470 - val_gender_output_acc: 0.8322 - val_image_quality_output_acc: 0.4743 - val_age_output_acc: 0.4073 - val_weight_output_acc: 0.6462 - val_bag_output_acc: 0.6562 - val_pose_output_acc: 0.8009 - val_footwear_output_acc: 0.5892 - val_emotion_output_acc: 0.7308\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0006926187.\n",
            "180/180 [==============================] - 100s 554ms/step - loss: 6.4826 - gender_output_loss: 0.3588 - image_quality_output_loss: 0.8827 - age_output_loss: 1.3366 - weight_output_loss: 0.9206 - bag_output_loss: 0.7759 - pose_output_loss: 0.5193 - footwear_output_loss: 0.8198 - emotion_output_loss: 0.8690 - gender_output_acc: 0.8418 - image_quality_output_acc: 0.5780 - age_output_acc: 0.4246 - weight_output_acc: 0.6457 - bag_output_acc: 0.6692 - pose_output_acc: 0.7958 - footwear_output_acc: 0.6240 - emotion_output_acc: 0.7073 - val_loss: 6.7652 - val_gender_output_loss: 0.3522 - val_image_quality_output_loss: 1.0950 - val_age_output_loss: 1.3603 - val_weight_output_loss: 0.9089 - val_bag_output_loss: 0.8059 - val_pose_output_loss: 0.5311 - val_footwear_output_loss: 0.8659 - val_emotion_output_loss: 0.8458 - val_gender_output_acc: 0.8498 - val_image_quality_output_acc: 0.4531 - val_age_output_acc: 0.4068 - val_weight_output_acc: 0.6411 - val_bag_output_acc: 0.6683 - val_pose_output_acc: 0.7928 - val_footwear_output_acc: 0.5897 - val_emotion_output_acc: 0.7298\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0006926187.\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0005757429.\n",
            "180/180 [==============================] - 99s 553ms/step - loss: 6.4489 - gender_output_loss: 0.3501 - image_quality_output_loss: 0.8782 - age_output_loss: 1.3351 - weight_output_loss: 0.9189 - bag_output_loss: 0.7721 - pose_output_loss: 0.5124 - footwear_output_loss: 0.8154 - emotion_output_loss: 0.8668 - gender_output_acc: 0.8475 - image_quality_output_acc: 0.5799 - age_output_acc: 0.4182 - weight_output_acc: 0.6464 - bag_output_acc: 0.6724 - pose_output_acc: 0.7941 - footwear_output_acc: 0.6287 - emotion_output_acc: 0.7078 - val_loss: 6.7708 - val_gender_output_loss: 0.3452 - val_image_quality_output_loss: 1.0509 - val_age_output_loss: 1.3658 - val_weight_output_loss: 0.9079 - val_bag_output_loss: 0.8003 - val_pose_output_loss: 0.5387 - val_footwear_output_loss: 0.9182 - val_emotion_output_loss: 0.8438 - val_gender_output_acc: 0.8498 - val_image_quality_output_acc: 0.4738 - val_age_output_acc: 0.4088 - val_weight_output_acc: 0.6442 - val_bag_output_acc: 0.6704 - val_pose_output_acc: 0.7954 - val_footwear_output_acc: 0.5685 - val_emotion_output_acc: 0.7278\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0004758206.\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 6.4328 - gender_output_loss: 0.3444 - image_quality_output_loss: 0.8798 - age_output_loss: 1.3347 - weight_output_loss: 0.9133 - bag_output_loss: 0.7715 - pose_output_loss: 0.5023 - footwear_output_loss: 0.8199 - emotion_output_loss: 0.8668 - gender_output_acc: 0.8490 - image_quality_output_acc: 0.5858 - age_output_acc: 0.4217 - weight_output_acc: 0.6488 - bag_output_acc: 0.6719 - pose_output_acc: 0.8035 - footwear_output_acc: 0.6260 - emotion_output_acc: 0.7079 - val_loss: 6.7474 - val_gender_output_loss: 0.3483 - val_image_quality_output_loss: 1.0789 - val_age_output_loss: 1.3589 - val_weight_output_loss: 0.9134 - val_bag_output_loss: 0.8054 - val_pose_output_loss: 0.5300 - val_footwear_output_loss: 0.8650 - val_emotion_output_loss: 0.8476 - val_gender_output_acc: 0.8488 - val_image_quality_output_acc: 0.4567 - val_age_output_acc: 0.4093 - val_weight_output_acc: 0.6462 - val_bag_output_acc: 0.6658 - val_pose_output_acc: 0.7913 - val_footwear_output_acc: 0.5953 - val_emotion_output_acc: 0.7288\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0003909783.\n",
            "179/180 [============================>.] - ETA: 0s - loss: 6.4304 - gender_output_loss: 0.3437 - image_quality_output_loss: 0.8791 - age_output_loss: 1.3330 - weight_output_loss: 0.9176 - bag_output_loss: 0.7701 - pose_output_loss: 0.5008 - footwear_output_loss: 0.8177 - emotion_output_loss: 0.8685 - gender_output_acc: 0.8501 - image_quality_output_acc: 0.5797 - age_output_acc: 0.4215 - weight_output_acc: 0.6459 - bag_output_acc: 0.6727 - pose_output_acc: 0.8039 - footwear_output_acc: 0.6281 - emotion_output_acc: 0.7086\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 32/100\n",
            "180/180 [==============================] - 100s 555ms/step - loss: 6.4300 - gender_output_loss: 0.3431 - image_quality_output_loss: 0.8795 - age_output_loss: 1.3329 - weight_output_loss: 0.9173 - bag_output_loss: 0.7702 - pose_output_loss: 0.5002 - footwear_output_loss: 0.8173 - emotion_output_loss: 0.8695 - gender_output_acc: 0.8504 - image_quality_output_acc: 0.5791 - age_output_acc: 0.4216 - weight_output_acc: 0.6463 - bag_output_acc: 0.6725 - pose_output_acc: 0.8043 - footwear_output_acc: 0.6281 - emotion_output_acc: 0.7082 - val_loss: 6.7173 - val_gender_output_loss: 0.3441 - val_image_quality_output_loss: 1.0686 - val_age_output_loss: 1.3568 - val_weight_output_loss: 0.9145 - val_bag_output_loss: 0.7997 - val_pose_output_loss: 0.5228 - val_footwear_output_loss: 0.8646 - val_emotion_output_loss: 0.8463 - val_gender_output_acc: 0.8478 - val_image_quality_output_acc: 0.4526 - val_age_output_acc: 0.4098 - val_weight_output_acc: 0.6416 - val_bag_output_acc: 0.6714 - val_pose_output_acc: 0.8034 - val_footwear_output_acc: 0.5817 - val_emotion_output_acc: 0.7288\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0003909783.\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0003194267.\n",
            "180/180 [==============================] - 99s 552ms/step - loss: 6.4052 - gender_output_loss: 0.3387 - image_quality_output_loss: 0.8813 - age_output_loss: 1.3295 - weight_output_loss: 0.9109 - bag_output_loss: 0.7634 - pose_output_loss: 0.5021 - footwear_output_loss: 0.8093 - emotion_output_loss: 0.8700 - gender_output_acc: 0.8556 - image_quality_output_acc: 0.5793 - age_output_acc: 0.4238 - weight_output_acc: 0.6471 - bag_output_acc: 0.6766 - pose_output_acc: 0.8055 - footwear_output_acc: 0.6274 - emotion_output_acc: 0.7075 - val_loss: 6.7551 - val_gender_output_loss: 0.3455 - val_image_quality_output_loss: 1.0664 - val_age_output_loss: 1.3618 - val_weight_output_loss: 0.9165 - val_bag_output_loss: 0.8081 - val_pose_output_loss: 0.5176 - val_footwear_output_loss: 0.8918 - val_emotion_output_loss: 0.8473 - val_gender_output_acc: 0.8533 - val_image_quality_output_acc: 0.4763 - val_age_output_acc: 0.4093 - val_weight_output_acc: 0.6331 - val_bag_output_acc: 0.6603 - val_pose_output_acc: 0.8044 - val_footwear_output_acc: 0.5801 - val_emotion_output_acc: 0.7283\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002594855.\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 6.4187 - gender_output_loss: 0.3426 - image_quality_output_loss: 0.8780 - age_output_loss: 1.3320 - weight_output_loss: 0.9121 - bag_output_loss: 0.7650 - pose_output_loss: 0.5055 - footwear_output_loss: 0.8159 - emotion_output_loss: 0.8676 - gender_output_acc: 0.8508 - image_quality_output_acc: 0.5852 - age_output_acc: 0.4219 - weight_output_acc: 0.6483 - bag_output_acc: 0.6775 - pose_output_acc: 0.8012 - footwear_output_acc: 0.6278 - emotion_output_acc: 0.7082 - val_loss: 6.6807 - val_gender_output_loss: 0.3388 - val_image_quality_output_loss: 1.0445 - val_age_output_loss: 1.3598 - val_weight_output_loss: 0.9134 - val_bag_output_loss: 0.7966 - val_pose_output_loss: 0.5275 - val_footwear_output_loss: 0.8558 - val_emotion_output_loss: 0.8443 - val_gender_output_acc: 0.8619 - val_image_quality_output_acc: 0.4844 - val_age_output_acc: 0.4088 - val_weight_output_acc: 0.6361 - val_bag_output_acc: 0.6724 - val_pose_output_acc: 0.8014 - val_footwear_output_acc: 0.5922 - val_emotion_output_acc: 0.7273\n",
            "Epoch 35/100\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0002096006.\n",
            "180/180 [==============================] - 100s 556ms/step - loss: 6.4200 - gender_output_loss: 0.3440 - image_quality_output_loss: 0.8783 - age_output_loss: 1.3291 - weight_output_loss: 0.9128 - bag_output_loss: 0.7688 - pose_output_loss: 0.5024 - footwear_output_loss: 0.8164 - emotion_output_loss: 0.8682 - gender_output_acc: 0.8530 - image_quality_output_acc: 0.5824 - age_output_acc: 0.4252 - weight_output_acc: 0.6464 - bag_output_acc: 0.6740 - pose_output_acc: 0.8026 - footwear_output_acc: 0.6260 - emotion_output_acc: 0.7076 - val_loss: 6.7540 - val_gender_output_loss: 0.3397 - val_image_quality_output_loss: 1.1026 - val_age_output_loss: 1.3610 - val_weight_output_loss: 0.9095 - val_bag_output_loss: 0.7980 - val_pose_output_loss: 0.5188 - val_footwear_output_loss: 0.8758 - val_emotion_output_loss: 0.8485 - val_gender_output_acc: 0.8548 - val_image_quality_output_acc: 0.4451 - val_age_output_acc: 0.4113 - val_weight_output_acc: 0.6411 - val_bag_output_acc: 0.6668 - val_pose_output_acc: 0.7999 - val_footwear_output_acc: 0.5817 - val_emotion_output_acc: 0.7288\n",
            "Epoch 00035: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f349c588438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9Qcz9_GQANw",
        "colab_type": "code",
        "outputId": "2c4d11d5-64c1-489d-bb0f-d4a5b4381834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "def evaluate_model(model):\n",
        "  results = model.evaluate_generator(valid_gen, verbose=1)\n",
        "  accuracies = {}\n",
        "  losses = {}\n",
        "  for k, v in zip(model.metrics_names, results):\n",
        "    if k.endswith('acc'):\n",
        "      accuracies[k] = round(v * 100, 4)\n",
        "    else:\n",
        "      losses[k] = v\n",
        "  return accuracies\n",
        "\n",
        "evaluate_model(model)\n",
        "\n",
        "# results = model.evaluate_generator(valid_gen, verbose =1)\n",
        "# dict(zip(model.metrics_names, results))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 5s 163ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age_output_acc': 41.129,\n",
              " 'bag_output_acc': 66.6835,\n",
              " 'emotion_output_acc': 72.8831,\n",
              " 'footwear_output_acc': 58.1653,\n",
              " 'gender_output_acc': 85.4839,\n",
              " 'image_quality_output_acc': 44.506,\n",
              " 'pose_output_acc': 79.9899,\n",
              " 'weight_output_acc': 64.1129}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-nJYdSOQAGn",
        "colab_type": "code",
        "outputId": "9295a0ae-33f8-44d1-f678-977cd948e971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,1,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    # axs[0].plot(range(1,len(model_history.history.history['acc'])+1),model_history.history['acc'])\n",
        "    # axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    # axs[0].set_title('Model Accuracy')\n",
        "    # axs[0].set_ylabel('Accuracy')\n",
        "    # axs[0].set_xlabel('Epoch')\n",
        "    # axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    # axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs.plot(range(1,len(model_history.history.history['loss'])+1),model_history.history.history['loss'])\n",
        "    axs.plot(range(1,len(model_history.history.history['val_loss'])+1),model_history.history.history['val_loss'])\n",
        "    axs.set_title('Model Loss')\n",
        "    axs.set_ylabel('Loss')\n",
        "    axs.set_xlabel('Epoch')\n",
        "    axs.set_xticks(np.arange(1,len(model_history.history.history['loss'])+1),len(model_history.history.history['loss'])/10)\n",
        "    axs.legend(['train', 'val'], loc='best')\n",
        "    plt.show()\n",
        "# plot model history\n",
        "plot_model_history(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAFNCAYAAABfWL0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3zV5fn/8dedTULIyWBmkACRvSQs\nxS24QetubV3VDvtta8ev9tt+u7fWql2KVatWba1aQesCRYKgaED2hhAIMwkJhJ1x//64TyBgwJCc\ncz4557yfj0ceJ3zmBYIPLu7rvi5jrUVEREREREQiV4zXAYiIiIiIiEhwKfETERERERGJcEr8RERE\nREREIpwSPxERERERkQinxE9ERERERCTCKfETERERERGJcEr8RERETsIYk2+MscaYuFZce4sx5r1Q\nxCUiInIqlPiJiEjEMMZsNMYcNsZkHXf8Y3/ylu9NZKeWQIqIiASaEj8REYk0pcCNTT8wxgwFkr0L\nR0RExHtK/EREJNI8DXyh2Y9vBp5qfoExJs0Y85QxpsIYU2aM+aExJsZ/LtYYc58xptIYswG4rIV7\nHzPGbDPGbDHG/MIYE9uegI0xicaYB4wxW/1fDxhjEv3nsowxrxpjaowxu4wxc5rF+j1/DLXGmNXG\nmAvaE4eIiEQuJX4iIhJpPgC6GGMG+hOyG4B/HHfNH4E0oA9wDi5RvNV/7g7gcmAkUARcc9y9fwfq\ngX7+ayYBX2xnzD8AxgEjgOHAGOCH/nPfBsqBrkB34H8Ba4zpD3wNGG2tTQUuAja2Mw4REYlQSvxE\nRCQSNa36TQRWAluaTjRLBr9vra211m4Efg983n/JdcAD1trN1tpdwK+b3dsduBT4prV2n7V2J/AH\n//Pa43PAz6y1O621FcBPm8VTB/QEeltr66y1c6y1FmgAEoFBxph4a+1Ga+36dsYhIiIRSomfiIhE\noqeBzwK3cFyZJ5AFxANlzY6VAdn+73sBm48716S3/95t/tLLGuARoFs74+3VQjy9/N/fC6wD3jLG\nbDDG3ANgrV0HfBP4CbDTGPNPY0wvREREWqDET0REIo61tgzX5OVS4KXjTlfiVtF6NzuWx9FVwW1A\n7nHnmmwGDgFZ1lqf/6uLtXZwO0Pe2kI8W/0/l1pr7bettX2AycC3mvbyWWuftdZO8N9rgd+2Mw4R\nEYlQSvxERCRS3Q6cb63d1/ygtbYBeB74pTEm1RjTG/gWR/cBPg983RiTY4xJB+5pdu824C3g98aY\nLsaYGGNMX2PMOacQV6IxJqnZVwzwHPBDY0xX/yiKHzXFY4y53BjTzxhjgN24Es9GY0x/Y8z5/iYw\nB4EDQOMp/hqJiEiUUOInIiIRyVq73lpbcoLT/wPsAzYA7wHPAo/7zz0KvAksBhbyyRXDLwAJwAqg\nGngBtwevtfbikrSmr/OBXwAlwBJgqf+9v/BfXwjM9N/3PvAXa+0s3P6+3+BWMLfjyk2/fwpxiIhI\nFDFuf7iIiIiIiIhEKq34iYiIiIiIRDglfiIiIiIiIhFOiZ+IiIiIiEiEC1riZ4x53Biz0xizrNmx\nDGPMDGPMWv9n+gnuvdl/zVpjzM3BilFERERERCQaBHPF7+/Axccduwd421pbCLxNsxbZTYwxGcCP\ngbHAGODHJ0oQRURERERE5NPFBevB1tpiY0z+cYenAOf6v38SeBf43nHXXATMsNbuAjDGzMAlkM+d\n7H1ZWVk2P//414mIiIiIiESHBQsWVFpru7Z0LmiJ3wl09w+/BTdzqHsL12QDm5v9uNx/7KTy8/Mp\nKTnRuCYREREREZHIZowpO9E5z5q7WDdAsF1DBI0xdxpjSowxJRUVFQGKTEREREREJLKEOvHbYYzp\nCeD/3NnCNVuA3GY/zvEf+wRr7VRrbZG1tqhr1xZXNEVERERERKJeqBO/6UBTl86bgWktXPMmMMkY\nk+5v6jLJf0xERERERETaIGh7/Iwxz+EauWQZY8pxnTp/AzxvjLkdKAOu819bBHzZWvtFa+0uY8zP\ngY/8j/pZU6MXERERERGRE6mrq6O8vJyDBw96HUpQJSUlkZOTQ3x8fKvvMW6rXfgrKiqyau4iIiIi\nIhK9SktLSU1NJTMzE2OM1+EEhbWWqqoqamtrKSgoOOacMWaBtbaopfs8a+4iIiIiIiISSAcPHozo\npA/AGENmZuYpr2oq8RMRERERkYgRyUlfk7b8HJX4iYiIiIiIBEBNTQ1/+ctfTvm+Sy+9lJqamiBE\ndJQSPxERERERkQA4UeJXX19/0vtee+01fD5fsMICgtjVU0Q8ULUeGhug62leRyIiIiISde655x7W\nr1/PiBEjiI+PJykpifT0dFatWsWaNWu48sor2bx5MwcPHuQb3/gGd955JwD5+fmUlJSwd+9eLrnk\nEiZMmMC8efPIzs5m2rRpdOrUqd2xacVPJJL8+xZ4+cteRyEiIiISlX7zm9/Qt29fFi1axL333svC\nhQt58MEHWbNmDQCPP/44CxYsoKSkhIceeoiqqqpPPGPt2rXcddddLF++HJ/Px4svvhiQ2LTiJxIp\nqtbD9iXQKd3rSEREREQ899NXlrNi656APnNQry78+IrBrb5+zJgxx4xceOihh/jPf/4DwObNm1m7\ndi2ZmZnH3FNQUMCIESMAGDVqFBs3bmx/4CjxE4kcK6e7zwPVcGgvJHb2Nh4RERGRKJeSknLk+3ff\nfZeZM2fy/vvvk5yczLnnntviSIbExMQj38fGxnLgwIGAxKLETyRSrJgGGMDC7s3QbaDXEYmIiIh4\n5lRW5gIlNTWV2traFs/t3r2b9PR0kpOTWbVqFR988EFIY1PiJxIJqstg68cw4HJY9SrUbFLiJyIi\nIhJimZmZnHnmmQwZMoROnTrRvXv3I+cuvvhiHn74YQYOHEj//v0ZN25cSGNT4icSCZrKPMd/7Wji\nJyIiIiIh9+yzz7Z4PDExkddff73Fc037+LKysli2bNmR49/5zncCFpe6eopEghXToedwyB0LsQmu\n1FNERERExE+Jn0i4270Fyj+EQVMgJgbScrTiJyIiIiLHUOInEu5WvuI+B05xn2m5UKMVPxERERE5\nSomfSLhbMQ26DYasfu7HvlyVeoqIiIjIMZT4iYSz2u2w6X1X5tnE1xv27oC6T86FEREREZHopMRP\nJJytfAWwxyZ+abnuc3e5JyGJiIiISMejxE8knK2cDln9oduAo8d8/sSvpsybmERERESkVTp37hyy\ndynxEwlX+yph43vHrvYB+PLcp/b5iYiIiIifBriLhKtVr4JthEGTjz2e2gtMrDp7ioiIiITYPffc\nQ25uLnfddRcAP/nJT4iLi2PWrFlUV1dTV1fHL37xC6ZMmfIpTwo8rfiJhKsV0yCjD3Qfcuzx2Djo\n0kuz/ERERERC7Prrr+f5558/8uPnn3+em2++mf/85z8sXLiQWbNm8e1vfxtrbchj04qfSDjavws2\nzIYzvw7GfPK8L0+lniIiIhLdXr8Hti8N7DN7DIVLfnPC0yNHjmTnzp1s3bqViooK0tPT6dGjB3ff\nfTfFxcXExMSwZcsWduzYQY8ePQIb26dQ4icSjla/Brbhk/v7mqTluv1/IiIiIhJS1157LS+88ALb\nt2/n+uuv55lnnqGiooIFCxYQHx9Pfn4+Bw+GfuyWEj+RcLRiulvV6zmi5fO+PKjdCg11EBsf2thE\nREREOoKTrMwF0/XXX88dd9xBZWUls2fP5vnnn6dbt27Ex8cza9Ysysq86byuPX4i4ebgblj/jlvt\na6nME9xIB9sIe7aENjYRERGRKDd48GBqa2vJzs6mZ8+efO5zn6OkpIShQ4fy1FNPMWDAgE9/SBBo\nxU8k3Kx+AxrrYOBJukE1DXGv2Qzp+SEJS0REREScpUuP7i3Mysri/fffb/G6vXv3hiokrfiJhJ0V\n06BLNmSPOvE1TbP81NlTRERERPAo8TPGfMMYs8wYs9wY880Wzp9rjNltjFnk//qRF3GKdDiHamHd\nTBg4GWJO8sc3Lcd9qrOniIiIiOBBqacxZghwBzAGOAy8YYx51Vq77rhL51hrLw91fCId2po3oeHQ\nibt5NolLhM49NMRdRERERABvVvwGAvOttfuttfXAbOAzHsQhEn5WTncJXe7YT7/Wlwc13nSNEhER\nEfGKF8PRQ60tP0cvEr9lwFnGmExjTDJwKZDbwnXjjTGLjTGvG2MGhzZEkQ7o8D5YOwMGXnHyMs8m\nvlyVeoqIiEhUSUpKoqqqKqKTP2stVVVVJCUlndJ9IS/1tNauNMb8FngL2AcsAhqOu2wh0Ntau9cY\ncynwMlB4/LOMMXcCdwLk5eUFNW4Rz62bCXX7YdDk1l2flusawTQ2QExscGMTERER6QBycnIoLy+n\noqLC61CCKikpiZycnFO6x5NxDtbax4DHAIwxvwLKjzu/p9n3rxlj/mKMybLWVh533VRgKkBRUVHk\npvUi4JK45CzIO6N11/vyoLEeardDWnZwYxMRERHpAOLj4ykoKPA6jA7Jq66e3fyfebj9fc8ed76H\nMW4ytTFmDC7OqlDHKdJh1B1wjV0GXg6xrfz3mqaRDir3FBEREYl6Xg1wf9EYkwnUAXdZa2uMMV8G\nsNY+DFwDfMUYUw8cAG6wkVyoK/Jp1r8Dh/d+ejfP5prP8ssbF5y4RERERCQseFXqeVYLxx5u9v2f\ngD+FNCiRjmzFdOiUDvmf+KNzYk2z/DTEXURERCTqeVLqKSKnoP4QrH4dBlwGsfGtvy8hBZIzVeop\nIiIiIkr8JES2LYHfD4Ady72OJPxsmA2HdsOgK0/9Xl+eVvxERERERImfhMi7v4babbD4Oa8jCT8r\npkFiGhScc+r3puVCjVb8RERERKKdEj8Jvu1LYfVrEBPvkhj16Wm9hjpY9Sr0vwTiEk79fl+eK/XU\nr7mIiIhIVFPiJ8FXfB8kdoGJP3Vlh1s/9jqi8FFaDAdrTq2bZ3O+PKg/CPsie4ipiIiIiJycEj8J\nrorVbpVvzB0w/EaIiXM/ltZZOR0SOkPf89t2f1qu+1S5p4iIiEhUU+InwVV8H8Qnw7i7IDnD7VNT\nuWfrNNTDylfhtIshPqltz/D5E7/davAiIiIiEs2U+EnwVK2HZS/A6NsgJdMdGzQFqkvdvj85uU3z\nYH9l28s8odmKnxI/ERERkWimxE+CZ879EJsA4//n6LEBl4OJVblna6yY5lZL+13Y9md08rmOoCr1\nFBEREYlqSvwkOKrLYMk/YdQtkNr96PGUTMifACteVrnnyTQ2wMpXoHAiJCS371m+XA1xFxEREYly\nSvwkOOY+ACYGzvj6J88NmgJV62DnitDHFS42z4e9O9pX5tlEQ9xFREREop4SPwm8PVvh43/AiM9B\nWvYnzw+8wiWFKvc8sRXTIS4JCie1/1lNQ9y1wioiIiIStZT4SeDNfRBsI0y4u+XznbtB7zOV+J1I\nY6Mb49DvQkhMbf/zfHlwuBYOVLf/WSIiIiISlpT4SWDt3QkL/g7DboD03ie+btAUqFgFO1eFLLSw\nsWUB7NkSmDJPaDbSQfv8RERERKKVEj8JrHl/hIbDcNa3Tn7dwCsAo1W/lqx4GWLi4bSLAvM8DXEX\nERERiXpK/CRw9lXBR4/BkKshs+/Jr03tAXnjlfgdz1q3v6/v+ZCUFphn+vwrr2rwIiIiIhK1lPhJ\n4HzwF6jbD2d9p3XXD5oCO5dD5drgxhVOtn4MuzcFrswTIDnDzQNUqaeIiIhI1FLiJ4FxoAY+nAqD\nJkO3Aa27Z+AV7lOrfketnA4xcdD/ksA90xh/Z0+t+ImIiIhEKyV+EhgfToVDe1q/2gdu1EPOGLen\nTfxlntOg4By3ShdImuUnIiIiEtWU+En7Hap1ZZ6nXQI9h53avYOmwPalULU+OLGFkx3LYNeGwJZ5\nNvHlqtRTREREJIop8ZP2++hvbkbcOd899XubkpyV0wMbUzhaMc0Nth9wWeCfnZbr/hsdqg38s0VE\nRESkw1PiJ+1zeB/M+xP0vQCyR536/b5cd1+07/OzFpa/DPkTICUr8M/35blPjXQQERERiUpK/KR9\nFjwJ+yvh7Das9jUZNMV1s6wuC1xc4aZiFVStDU6ZJxxN/FTuKSIiIhKVlPhJ29UdhLkPQv5Z0Ht8\n258zcLL7jOZVvxXTAAMDrgjO84+s+KnBi4iIiEg0UuInbffx07B3e/tW+wAyCqDn8ChP/KZD7zMg\ntXtwnp/SDWITlPiJiIiIRCklftI29YfhvQcgdywUnN3+5w26EraUROcetMq1bpB9sMo8AWJiIC1H\npZ4iIiIiUUqJn7TN4udgTzmc/f/cgPD2OtLd85X2PyvcNK10DgxSmWcTzfITERERiVqeJH7GmG8Y\nY5YZY5YbY77ZwnljjHnIGLPOGLPEGHO6F3HKCTTUw3v3Q6+R0O+CwDwzsy90Hxqdw9xXTHOD7Lv0\nCu570nKjc0VVREREREKf+BljhgB3AGOA4cDlxph+x112CVDo/7oT+GtIg5STW/YCVG90e/sCsdrX\nZNAU2Dwf9mwN3DM7ul0bYPuS4JZ5NvHlwb6dUHcg+O8SERERkQ7FixW/gcB8a+1+a209MBv4zHHX\nTAGess4HgM8Y0zPUgUoLGhug+D7oPgT6XxrYZw++0n1GU7nnCv/g+kGTg/+uIyMdyoP/LhERERHp\nULxI/JYBZxljMo0xycClQO5x12QDzWvSyv3HjmGMudMYU2KMKamoqAhawNLMipfdvLmzvxPY1T6A\nrELoNii6unuunA69Tj+alAVTmv+Pmfb5iYiIiESdkCd+1tqVwG+Bt4A3gEVAQxufNdVaW2StLera\ntWsAo5QWNTa61b6s047O3gu0QVOgbB7U7gjO8zuSmk2wZUFoyjwBfP7ET509RURERKKOJ81drLWP\nWWtHWWvPBqqBNcddsoVjVwFz/MfES6tfg50r4KzvQExscN4xaApg3UpYpGsqaQ1FmSdAai8wsVrx\nExEREYlCXnX17Ob/zMPt73v2uEumA1/wd/ccB+y21m4LcZjSnLVQ/DtIL4AhVwfvPV0HuBXFaCj3\nXDENegyFjD6heV9sHHTJVmdPERERkSjk1Ry/F40xK4BXgLustTXGmC8bY77sP/8asAFYBzwKfNWj\nOKXJ2hmwbTGc9W2XQASLMW6Ye9lc2BvB+zb3bHUdTENV5tnEl6dSTxEREZEoFMS/wZ+YtfasFo49\n3Ox7C9wV0qDkxJpW+9JyYdj1wX/foCnufatehaJbg/8+Lxwp87wytO/15UJpcWjfKSIiIiKe82rF\nT8JJ6Wwo/wgmfBPiEoL/vu6DIaNvZA9zXzHddTDNKgzte9NyoXYbNNSF9r0iIiIi4iklfvLpZt8L\nqT1hxE2heZ8xbtWvdA7sqwrNO0NpX6UrZQ1WZ9ST8eWBbYQ96pUkIiIiEk2U+MnJlc2DsvfgzG9A\nfFLo3jtoCtgGWP3f0L0zVEqLAQuFk0L/bp9m+YmIiIhEIyV+cnKzfwcpXeH0m0P73p7DIT0/Mrt7\nbpwDiV3czzHUjgxxV4MXERERkWiixE9OrLwENsyC8V+DhOTQvrup3HPDu3CgOrTvDrbSYuh9RnC7\no55IWg5gtOInIiIiEmWU+MmJFd8LndJh9O3evH/QFGish1WvefP+YNi9BarWQcHZ3rw/LhFSe2ik\ng4iIiEiUUeInLdu2GNa8AePugsRUb2LodborTYykcs+Nc9ynV4kfuF9TrfiJiIiIRBUlftKy4nsh\nMQ3G3uldDE3lnuvfgYO7vYsjkEqLoVMGdBvsXQy+PCV+IiIiIlFGiZ980o4VbsD42DshKc3bWAZd\nCY11sPoNb+MIBGtd4ldwFsR4+EfPl+vGOTQ2eBeDiIiIiISUEj/5pDm/h4TOMO6rXkcC2aOgS3Zk\nlHtWb3R76/LP8jYOX57bO1m73ds4RERERCRklPjJsSrXwfKXXEOX5Ayvo3ErYwMnw7qZcHCP19G0\nT2mx+yw4x9s40vLcp8o9RURERKKGEj851tw/QGwijP8fryM5atAUaDgEa9/yOpL2KS2Gzj0gq9Db\nOJqGuKuzp4iIiEjUUOInR+2rgiX/huE3QOeuXkdzVO5YlzCteNnrSNruyP6+s13TGi8dGeKuFT8R\nERGRaKHET45a+KRbWRvjYSfPlsTEwKDJsHYGHNrrdTRtU7Ea9u30doxDk4RkSM5S4iciIiISRZT4\nidNQDx895hqPdB/kdTSfNGgK1B8M33LPI/P7PG7s0sSXq1JPERERkSiixE+cNa/DnnIY+yWvI2lZ\n3nhI6Rq+3T1LZ7tumun5Xkfi+PKgRomfiIiISLRQ4ifO/Efc3q/TLvE6kpbFxMLAK9yK3+H9Xkdz\nahoboXROxyjzbJLmX/Gz1utIRERERCQElPiJG9i+cY4b4RAb53U0JzboSqjb70Y7hJMdS+Fgjfdj\nHJrz5bnS2X0VXkciIiIiIiGgxE/gw6kQlwSn3+x1JCfX+0xIzgy/cs+m+X1eD25vztc0y0/lniIi\nIiLRQIlftDtQDUv+BUOu6RgD208mNg4GXA5r3oC6A15H03qlcyCzELr09DqSo46MdCjzNg4RERER\nCQklftHu42dc+eTYDjbC4UQGTYHDe2H9O15H0joNdVA2t2Pt7wMNcRcRERGJMkr8olljA3z0KOSO\ng57DvY6mdQrOhk7p4VPuuXWRS1Q7WuKXlOa+NMtPREREJCoo8Ytma2dA9cbwWe0DiI2HAZfB6teh\n/pDX0Xy60tnusyPt72uSppEOIiIiItFCiV80+/ARSO0JAyd7HcmpGXQlHNoDG971OpJPV1oM3YdA\nSqbXkXySL0+lniIiIiJRQolftKpc6/bJFd3mVtHCScE5kJgGy1/2OpKTqz8Em+d3vDLPJr5cV+qp\nWX4iIiIiEU+JX7T6cCrEJsCoW7yO5NTFJcCAS2H1f6H+sNfRnFj5R25WXkdN/NJy3f7DA9VeRyIi\nIiIiQabELxod3AOLnoXBV0Hnbl5H0zaDroSDu4/OyOuISovBxEDvM7yOpGVNs/xU7ikiIiIS8TxJ\n/IwxdxtjlhtjlhljnjPGJB13/hZjTIUxZpH/64texBmxFv/TrfSM+ZLXkbRd3/MgIRVWdOByz9Ji\n6DXSdc/siJpGOqizp4iIiEjEC3niZ4zJBr4OFFlrhwCxwA0tXPova+0I/9ffQhpkJGtsdGWe2aMg\nZ5TX0bRdXCL0vwRWvepm5XU0h/dBeUnH7ObZJM2/4qfOniIiIiIRz6tSzzigkzEmDkgGtnoUR/TZ\nMAuq1sKYMBrhcCKDprj9aRvneB3JJ236ABrrOu7+PoDkDIhPUamniIiISBQIeeJnrd0C3AdsArYB\nu621b7Vw6dXGmCXGmBeMMbktPcsYc6cxpsQYU1JRURHEqCPIh1Mhpavb3xfu+l0ACZ075jD30mKI\niYe8cV5HcmLGHO3sKSIiIiIRzYtSz3RgClAA9AJSjDE3HXfZK0C+tXYYMAN4sqVnWWunWmuLrLVF\nXbt2DWbYkWFXKax503XyjEv0Opr2i+8Ep10EK1+FhnqvozlWaTHkjIaEFK8jObk0JX4iIiIi0cCL\nUs8LgVJrbYW1tg54CTim7aG1tspae8j/w78BYbwZrQP56G8QE+tm90WKQVNgfyVsmud1JEcdqIFt\nizp2mWcTDXEXERERiQpeJH6bgHHGmGRjjAEuAFY2v8AY07PZDycff17a4PA++PhpGHgFdOnldTSB\n028ixCfDspe8juSosnlgG6GgAzd2aeLLdfskD9V6HYmIiIiIBJEXe/zmAy8AC4Gl/himGmN+ZoyZ\n7L/s6/5xD4txHUBvCXWcEWfJv9zcu3Ae4dCShGQYOBmWvgCH9nodjbNxDsQluVLPjs6nzp4iIiIi\n0cCTrp7W2h9bawdYa4dYaz9vrT1krf2RtXa6//z3rbWDrbXDrbXnWWtXeRFnxLAW5k+FHkM7drOR\nthp9OxyuhaX/9joSp7TY/TqHwz7KIyMdtM9PREREJJJ5Nc5BQmnjHKhY6Vb7jPE6msDLGQ3dh0DJ\n4y7J9dK+StixLDz298HRIe7a5yciIiIS0ZT4RYMPp0KnDBh6jdeRBIcxUHQrbF8CWxZ6G0vTTMGC\nc7yNo7VSukFsolb8RERERCKcEr9IV7MZVv0XTv+CG38QqYZe54aRlzzubRylxZCQCj1HeBtHa8XE\nQFqOEj8RERGRCKfEL9KVPOY+R9/ubRzBltQFhl0Hy150XSq9UjoHep8BsXHexXCqfLkq9RQRERGJ\ncEr8IlndAVjwJPS/9Gj3xkhWdCvUH4DF//Tm/Xu2QtXa8Nnf18SXp66eIiIiIhFOiV8kW/YiHNgF\nY+70OpLQ6Dkcsou8a/JS2rS/L8wSv7Q82LfT/UNBJDm0F6rLvI5CREREpENQ4heprIX5j0DXgeGX\niLRH0W1QuQbK5ob+3aXF0CnddRgNJ0c6e5Z7G0cgWQv/vBEePQ8a6r2ORkRERMRzSvwi1eb5rsvl\nmDsic4TDiQy+CpLSQt/kxVoonQ35E1zDlHDii8BZfgv+7hLx/VVQ/qHX0YiIiIh4Lsz+hiqtNv8R\nSEyDYdd7HUloJSTDiM/Biumwd2fo3lu90TVICZcxDs2l+Vf8IiXxq9kMb/0f5I6DmDhY+5bXEYmI\niIh4TolfJNqzDVZOh5E3QWJnr6MJvVG3QmMdfPyP0L1zY5ju7wNI7ekSpEjo7GktvPpNsA3wmUcg\nbzysnel1VCIiIiKeU+IXiUoeh8YGGPNFryPxRtfTIP8sWPAENDaG5p2lxdC5O2SdFpr3BVJsHHTp\nFRmdPRc/B+tmwoU/gfR8KJwIO5a6jqsiIiIiUUyJX7Adqg3t++oPuYSncBJk9AntuzuSoltd6eL6\nd4L/Lmtd4ldwdvjup0zLC/9Sz9rt8MY9rsRz9B3uWL+J7nPtDO/iEhEREekAWpX4GWP6GmMS/d+f\na4z5ujHGF9zQIsDKV+ChkbDqtdC9c8U02FcBY6NkhMOJDLgCUroeHWAfTJVrYO8Ot8oYrnx54V3q\naS28+i33Dx9T/ny0wU63gdAlR/v8REREJOq1dsXvRaDBGNMPmArkAs8GLapIkdEXOvdwbeWn3RWa\n1b/5j7j39jk/+O/qyOISYOHUnwMAACAASURBVOTnYc0bwR9TUFrsPsNxf18TXy7UboP6w15H0jbL\nX4LV/4Xz/hey+h09bowr99zwbvj+3EREREQCoLWJX6O1th64Cvijtfa7QM/ghRUhug+CO96BCd+C\nRc/CX8+AsnnBe9+WBbClxA1sD7eRAsEw6ma3ErTwqeC+p7TYlUqm5wf3PcGUlgu2EfZs8TqSU7ev\nEl77LmSPgvFf++T5wklweC9s/iD0sYmIiIh0EK3NDuqMMTcCNwOv+o/FByekCBOXABf+GG59HUwM\nPHGpazVffyjw75o/FRI6w4jPBv7Z4Sg9H/pdCAuehIa64LyjsdF19Azn/X1wdJZfOJZ7vvZdOLjH\nX+IZ+8nzBWdDbILKPUVERCSqtTbxuxUYD/zSWltqjCkAng5eWBEobxx8eS6MugXmPQRTz4XtSwP3\n/L0Vrtxt+I2Q1CVwzw13RbfB3u2w+vXgPH/HMjhQHd5lnuBKPSH8GrysfMX9vj/ne24/X0sSO0Pv\nM9TgRURERKJaqxI/a+0Ka+3XrbXPGWPSgVRr7W+DHFvkSewMVzwAn/037K+CqefBnPvd6IX2WvB3\naDjsyjzlqNMucs09Sh4PzvOP7O8L48Yu4H6NMOE10mH/Lvjvt6HHUJjwzZNfWzgJKlaFX2IrIiIi\nEiCt7er5rjGmizEmA1gIPGqMuT+4oUWw0ybBV96HAZfC2z+FJy6BXRva/ryGOte9ss95boadHBUT\n6/b6bZgFVesD//zSYsjs5+bghbO4BDfIPZxKPd/8gfsHlCl/hthPqTwvnOQ+teonIiIiUaq1pZ5p\n1to9wGeAp6y1Y4ELgxdWFEjJhGufhM88CjtXwV8nQMkTrhnJqVr5iuvIOPZLgY8zEoz8PJhYtyoa\nSA31rllPuJd5NvHlhs+K2NoZsPhZmHA39Bz+6ddn9nN7PpX4iYiISJRqbeIXZ4zpCVzH0eYu0l7G\nwLDr4KvzIKcIXv0mPHs91O44ted8OBV8vY+uasixuvR0q6sf/wPqDgbuudsWweHaCEr8wmSI+8Hd\n8Mo3oOsAOPu7rbvHGDfMvXR2YH8PiIiIiISJ1iZ+PwPeBNZbaz8yxvQB1gYvrCiTlgOffxku/q37\ni+lfxsHyl1t377YlsOl9GHNHyx0NxSm6HQ7sgpXTA/fM0tnuM5wHtzeXluvGOQRiz2kwzfiRW+Ge\n8meIS2z9fYWToG4/lM0NXmwiIiIiHVRrm7v821o7zFr7Ff+PN1hrrw5uaFEmJgbGfRm+NAfSe8O/\nb4aX7oQDNSe/78NHIK4TjLwpNHGGq4JzIKNPYJu8lBZDt8GQkhW4Z3rJlwuN9S6p6qg2vOtKdsff\n5VbJT0X+BIhLUrmniIiIRKXWNnfJMcb8xxiz0//1ojEmJ9jBRaWup8HtM+Dc78PSF9zQ9w3vtnzt\n/l3ummHXQaf0kIYZdmJiYNStbnV0x4r2P6/+EGz6IHLKPOHoLL+O2tnz0F6Y/nXI6Avn/eDU709I\ndquz65T4iYiISPRpbannE8B0oJf/6xX/MQmG2Hg49x744gyIT4anpsDr34O6A8det/ApqD+opi6t\nNeJzEJsICwLwW7e8xP3aR1Lil9bBh7i/83O3B3HKnyG+U9ueUTgJqtYFp8OriIiISAfW2sSvq7X2\nCWttvf/r70DXIMYlANmj4EvFMPbLMP9heORs2LLAnWtsgI8eg94ToPtgb+MMFymZMPhKWPxPt3rU\nHqXFYGLcYPBIkeZfxK8p8zaOlpS9D/MfcXMqe49v+3MK/c2I180MTFwiIiIiYaK1iV+VMeYmY0ys\n/+smoKqtLzXG3G2MWW6MWWaMec4Yk3Tc+URjzL+MMeuMMfONMfltfVfYS0iGS37rmr8c3gd/mwjv\n/saNcNi9CcZqYPspKboNDu2BZS+27zmlxdBzBHTyBSaujiAhGVK6drxSz7oDMO0utwfxgh+171kZ\nfdxoh7VvBSY2ERERkTDR2sTvNtwoh+3ANuAa4Ja2vNAYkw18HSiy1g4BYoEbjrvsdqDaWtsP+APw\n27a8K6L0PQ++MheGXA3v/hpeuA265ED/y7yOLLzkjoVug9rX5OXwPij/CAoipJtnc2m5Ha/Uc9av\nYNd6mPxHSOzc/ucVToLSOXB4f/ufJSIiIhImWtvVs8xaO9la29Va281aeyXQnq6ecUAnY0wckAxs\nPe78FOBJ//cvABcYY0w73hcZOqXD1Y/CtX93KzNn3Q2xcV5HFV6Mcat+2xbBloVte8amD6CxLrL2\n9zXpaEPcyxfA+3+C02+GPucG5pmFE6HhEGx8LzDPExEREQkDrV3xa8m32nKTtXYLcB+wCbd6uNta\ne3zdVTaw2X99PbAbyGx7qN6oa2hkxopTHMbeGoOvgu+shtFfDPyzo8Gw61zTnJLH2nb/xjkQEwd5\n7dhr1lH58mB3OVjrdSSuc+q0uyC1J0z6eeCe2/tM999f5Z4iIiISRdqT+LVpBc4Yk45b0SvAdQhN\n8e8ZbMuz7jTGlBhjSioqKtryiKB6ct5G7niqhL/N2eB1KNJcUhoMvRaWvvjpcxJbUloMOaMhISXw\nsXktLc91K9270+tIoPheqFgJlz/g/psFSlyim+u49s2OkeCKiIiIhEB7Er+2/o3pQqDUWlthra0D\nXgKOb424BcgF8JeDptFCMxlr7VRrbZG1tqhr147XZPTmM/K5ZEgPfvHflUr+OpqiW6H+ACz516nd\nd3A3bP04Mss8wZV6gvf7/LYthjn3w/Ab4bRJgX9+4URX0lq5NvDPFhEREemATpr4GWNqjTF7Wviq\nxa3WtcUmYJwxJtm/b+8CYOVx10wHbvZ/fw3wjrXh90/z8bExPHTjSC4d6pK/R4uV/HUYvUZCr9Nd\nk5dT+a1VNg9soxsEHomODHH3cJ9fQ50r8UzOhIt+FZx3FE50nxrmLiIiIlHipImftTbVWtulha9U\na22buopYa+fjGrYsBJb6Y5hqjPmZMWay/7LHgExjzDrcXsJ72vKujiA+NoYHbxjJZUN78svXlPx1\nKEW3QcUql8y1VmkxxCW5Us9IlOZf8fMy8Zv7AGxfCpffD8kZwXmHLw+6DtQ+PxEREYkanrSEtNb+\nGPjxcYd/1Oz8QeDakAYVRPGxMTxwwwgAfvnaSiyWO8/u63FUwpCr4c0fuFW//DNbd0/pHDcSIj7p\n068NR0ldIMnnXannzpUw+3cw+DMw8IrgvqtwInzwVzi0NzBjIkREREQ6sPbs8ZNT0JT8XTa0J796\nbRWPzF7vdUiSkAwjboQV02BvK5oD7auCHUsjd39fE1+uN0PcGxtciWdiKlx6b/DfVzjRjeUonR38\nd4mIiIh4TIlfCLmyT5f8/fp1JX8dwqhb3V/+Fz3z6ddunOM+C84JbkxeS8vzptTz/T/DlgVwye8g\nJSv478sdBwmpKvcUERGRqKDEL8TimpK/YS75e1jJn7e6DXBz3RY8AY2NJ7+2tBgSOkOvEaGJzSu+\nPFfqGcp+SpXrYNYvof9lrgQ3FOISoO+5sHamxjqIiIhIxFPi54G42BgevH4Elw/ryW+U/Hmv6Dao\n3ggb3jn5daXF0PsMiI0PSVie8eXC4b1woDo072tshOlfc/P1Lr8fTJtGhLZN4STYU+72FoqIiIhE\nMCV+HomLjeGBZsnfX99V8ueZgVdAchaUPHHia/Zsg6q1kb+/D0Lf2fOjv8Gm9+Hi30Bqj9C8s0k/\n/1gHlXuKiIhIhFPi56Gm5O+K4b347Rur+Mu767wOKTrFJcLIm2D167B7S8vXHNnfFwWJX9Msv1B0\n9qzdDjN/Av0udMPaQ61LT+g+FNZqnp+IiIhENiV+HouLjeEP1w1n8vBe/O6N1Ur+vDLqFrAN8PHT\nLZ8vne3GHHQfGtKwPHFkiHsIEr+3f+6a61x6b2hLPJsrnOhWHA/u9ub9IiIiIiGgxK8DiIuN4f5m\nyd+fZyn5C7mMAuh7ASx4EhrqP3m+tBjyJ0BMFPyR6ZQO8SnBL/Xcush1Ux37JcjoE9x3nUzhJJf0\nb3jXuxhEREREgiwK/hYbHpqSvykjenHvm0r+PDH6dqjdCmveOPZ49UaXBEX6GIcmxhzt7Bks1sKb\nP4DkDDj7u8F7T2vkjIakNO3zExERkYgW53UAclRcbAy/v3Y4APe+uRqAu87r52VI0aXwIkjtBSWP\nw8DLjx4vLXaf0bC/r4kvN7grfqtehbL34LLfu6TLS7FxbrV37QyXkHpVcioiIiISRFrx62Cakr+m\nlb8/vbPW65CiR2wcjLoZ1r8Nu0qPHi+dAyndoGt/72ILNV8Qh7jXH4K3/g+6DoTTbwnOO05V4UTY\nuwO2L/E6EhEREZGgUOLXAbmyzxFcOaIX9721RslfKJ3+BTCxbqA7uBWg0mK32hdNK0FpuXCwBg7u\nCfyzP5wK1aVw0S9cst0R9LvQfaq7p4iIiEQoJX4dVGyM4ffNkr8/vq3kLyS69IL+l8DH/3ArU5Vr\nYe92KDjL68hCy+ef5RfofX77KmH2vW5+XlOy1RF07ga9RirxExERkYilxK8Da0r+rhqZze9nrOEh\nJX+hUXQb7K+Cla+4MQ4QXfv7AHy93WegRzq8+2s4vBcu+mVgnxsIhZOg/EPYv8vrSEREREQCTolf\nBxcbY7jv2uFcNTKb+5X8hUaf8yA93zV5KS12ZY/pBV5HFVppQVjx27kKSp5wiXVH3C/ZbyLYRlj/\njteRiIiIiAScEr8w0JT8fcaf/D04U8lfUMXEwKhboWyuK/2Ltv19ACldITYRasoC98y3fgAJneHc\n7wfumYGUfTp0ylC5p4iIiEQkJX5hIjbGcO+1w/nM6dn8YaaSv6AbeRPEJkD9gegr8wSX/PpyA1fq\nuXYmrJsJ5/w/SMkMzDMDLSbW7TtcNxMaG72ORkRERCSglPiFkdgYw73XHE3+rv7rPB6YuYaSjbuo\na9BfVAMqJQsGTXHf50dZY5cmabmBKfVsqHerfRl9YMyd7X9eMBVOgv2VsO1jryMRERERCagO0ktd\nWqsp+evbtTNvLd/Og2+v5YGZa0lJiGVcn0zO7JfFmf2yOK17Z0y0lScG2sSfuQ6fadleR+INXy6s\nfr39z1nwBFSsguufgbiE9j8vmPpdABhX7pk9yutoRERERAJGiV8Yio0x3HVeP+46rx81+w/zwYYq\n3ltXydx1Vby9aicAXVMTObOvSwQnFGbRM62Tx1GHoS69YMjVXkfhHV8e7KuAugMQ38bfPwdqYNav\n3KrpgMsCG18wJGdAThGsfQvOvcfraEREREQCRolfmPMlJ3DxkJ5cPKQnAOXV+5m3ziWC762r5OVF\nWwHo0zWFCf7VwHF9MknrFO9l2BIO0vLc5+5yyCps2zOK74UD1XDRr8KnQU7hJJes7qt0Jb8iIiIi\nEUCJX4TJSU/mutHJXDc6F2stq3fU8t7aSuauq+SFBeU89X4ZMQaG5fg4s59bERzVO53EuFivQ5eO\nxudP/GrK2pb4Va2H+Y/AyM9Bz2GBjS2YCifCrF/Curdh+PVeRyMiIiISEEr8IpgxhgE9ujCgRxe+\neFYfDtc3smhzDe+tq2Teukoenr2BP89aT1J8DKPzM46sCA7q2YWYmDBZnZHg8fln+bW1s+eMH7nO\nqOf/X+BiCoUewyGlmyv3VOInIiIiEUKJXxRJiIthTEEGYwoy+NbE06g9WMeHpbv8+wMr+fXrqwBI\nT45nfN9MxvfN4oy+mfTJSlGjmGiU2hNi4trW2bN0Dqx6Fc7/IaT2CHxswRQT41b9Vv0XGhvcmAcR\nERGRMKfEL4qlJsVzwcDuXDCwOwA79xxk7nrXJGbeukpeW7odgB5dkjijbybj+2ZyRr8ssn1qFBMV\nYmKhSzbUbDq1+xob4M3/deMgxn8tOLEFW78LYdEzUF4CeWO9jkZERESk3ZT4yRHduiRx1cgcrhqZ\ng7WWTbv2uyRwfSWz11Tw0sdbAMjPTD6yGji+byZZnRM9jlyCxpd36qWei5+D7Uvg6sfa3g3Ua33P\nAxML62Yo8RMREZGIoMRPWmSMoXdmCr0zU/js2LwjjWLmrati3voqXl28lec+dCtBA3qkutXAvlmM\n7ZNBlyR1DI0Yabmw4d3WX39oL7z9M8gZHd6jMDqlQ+5Yt8/v/B96HY2IiIhIu4U88TPG9Af+1exQ\nH+BH1toHml1zLjANKPUfesla+7OQBSmf0LxRzG0TCqhvaGTZ1j3MW1/JvHVVPDt/E0/M3UiMgaE5\nPs7om8kZfTMp6p1BpwTtkQpbvjyo3Qb1h1s3fH3uA7B3hxvWHu77Qgsnwts/hdrtHXeforWutNY2\nuM/G+mbfNx2vd98npmo8hYiISBQLeeJnrV0NjAAwxsQCW4D/tHDpHGvt5aGMTVovLjaGEbk+RuT6\n+Oq5/ThU38DHm2qYt97tD3y0eAN/fXc9CbExjMzzcUbfLM7ol8nQ7DSS4pUIhg1fLmBhzxbIKDj5\ntTWbYd4fYcg1kDs6JOEFVeEkl/itmwkjbwr++w7vg1fvhvKPjkvcTpLQ2cbWP9/EwLDr4ezvQmbf\n4P08REREpEPyutTzAmC9tbbM4ziknRLjYhnXJ5NxfTL51sTT2Heono827nKJ4PpKHnh7DX+YCXEx\nhgE9UxmR62N4jo+ReT76ZHXW+IiOKq1ppMOmT0/83v6p+7zwJ8GMKHS6D4bUXq7cM9iJ374qePY6\n2LoQBlwO8cmuuY6JcZ1VY2LdnsOYONd1NCbO/2P/MRPT7Ptm1x35Pha2L4OSx2HJ8y4BPOe7kNEn\nuD8vERER6TC8TvxuAJ47wbnxxpjFwFbgO9ba5aELS9orJTGOc/t349z+3QCo2X+Y+aW7WLy5hkWb\na3j546384wO3RzA1MY5huWkMz/ExPNfHyFwf3bokeRm+NGka4v5pIx3KS2Dpv+Gs7xyd/xfujIHC\nC2H5NGiog9gg7V2t2QRPf8Z9Xvc0DAxiocOZ34C5D0LJY7DkXzD8Rjj7O5+e1IuIiEjYM9Zab15s\nTAIuqRtsrd1x3LkuQKO1dq8x5lLgQWttYQvPuBO4EyAvL29UWZkWDsNFY6NlQ+VePt5Uw+LyGhZv\n3s3KbXuob3S/H3umJTE8x8eIPLcyOCwnjZREr/+dIgrVH4ZfdINzvgfnfb/la6yFxyZBTRn8z0JI\n7BzaGINp5Svwr5vgltcg/8zAP3/HcvjH1XB4P9z4XHDe0ZLa7fDeA24FsLEeRtzoSkDT80PzfhER\nEQkKY8wCa21Ri+c8TPymAHdZaye14tqNQJG1tvJE1xQVFdmSkpIARiihdrCugeVb97Bocw2LN7uE\nsKxqPwAxBgq7pTI8N40RuekMz02jf/dU4mJjPI46Ctw/CArOgav+2vL5pS/Ai7fD5D/B6Z8PbWzB\ndnAP/K4PjL8LJv40sM/eOBeeuxESkuGmF11paajt2Qbv/QEW/N3tGxzxWbdqm9479LGIiIhIu3XU\nxO+fwJvW2idaONcD2GGttcaYMcALQG97kmCV+EWmXfsOs7i8hkVHVgZrqN5fB0BSfAxDs12J6Om9\n0xnVO53uKhENvMcucmWOt7z6yXN1B+BPo6GTD+6c7faSRZonr3B78L46L3DPXPkKvHC7K6X9/EtH\nS2q9smdrswSwEUZ8zpWAeh2XiIiInJKTJX6e1M4ZY1KAicCXmh37MoC19mHgGuArxph64ABww8mS\nPolcGSkJnNe/G+f59wo2DZZf5N8ruHhzDU99UMbf3nOTP7J9nRjlTwJH9U5nQA+tCrabLxc2f9jy\nuff/7Pb/XfnXyEz6APpNhBn/B7vLIS2n/c8reRz++23odTp89nlIyWz/M9urSy+49F4485vw3v2w\n8ClY9KxranPWtyNn36aIiEgU82zFL9C04he9Dtc3snLbHkrKqllYVk1J2S527DkEQKf4WEbk+hjV\nO53Te/s4PS8dX3Ir5tHJUW//zDUE+eHOY5O72h3wx9Ohz7lwwzNeRRd8O1fBX8bCFQ/CqFva/hxr\nYfZv4d1fu1ER1/4dElICFWVg7S6HOf4EEOD0L8BZ3wpM4isiIiJB0+FW/EQCKSEuhuG5riPo7RMK\nsNaydfdBFvgTwQVl1fx19noa/I1j+nZNOWZVUOMkPkVarmsAUrvt2L/4v/NzqD8EE3/mXWyh0LU/\npOXB2hltT/waG9wq34InYPhnYfJDwesSGghpOXD5/TDhbpjze5cAfvy0SwAnfAvSsr2OUERERE6R\nEj+JOMYYsn2dyPZ1YvLwXgDsP1zP4s27WbjJJYJvrdjB8yXlAKR1iuf0vKZVwXRG5PpITtAfjSOa\nyvxqNh9N/LYtgY//4ZqeRPowcGOgcKIbf1B/COIST+3+uoPw0hfdvr4Jd8MFP3bPDAe+XLjiAbfa\nV3yf2wO48CmXAE+425WIioiISFjQ324lKiQnxDG+bybj+7r9VG6cxL4jK4ILNlUza3UFALExhoE9\nUxmV5xLB0fkZ9PJ18jJ8b/n8HR5rNkHv8a5k8c3/hU7pbgRANCic6GbfbXrflba21oEa+OdnoWwu\nXPRrGP/VYEUYXL48t0p51rfcCmDJ47DgyWYJYE+vIxQREZFPocRPolJMjKFft87069aZ60a7Fa2a\n/Yf5eFONSwTLqnm+pJwn33ezIZuaxozOT6coP4PTuqcSGy3loU2rfLs3uc/Vr8HGOXDpfa6bZzQo\nOBtiE1y5Z59zW3fPnm1uRl/lGrj6MRh6TTAjDI30fJj8R1fuOec++OhvbhWwS0+ITYS4BP9novv1\nik345LG4RFfm+oljCcfdlwg9h2tVUUREJEDU3EXkBOobGlm5rZaSsl2UbKzmo4272FnrmsakJsUx\nqnc6Rb1dIjgi10dSfIR2tQS4tx/0v9Qle38ZCzHx8JV5EBtF/3b09FWwewt87QQdTpurXAtPfwYO\n7ILrn4a+5wc/Pi/s2gAf/g327YSGw1B/GBoOHf1s6Vj9YXe84ZAbHXEynTLgS8XqKioiItJKau4i\n0gZxsTEMzUljaE4at57pmsaUVx/go427+GhjNSUbd/Guvzw0PtYwJDuN0fkZRxLCzM6nuBesI/Pl\nuVLPjx51f9n/3AvRlfSB68T5xj1QvdGtfJ1IeQk8c63rgHrLq9BrZKgiDL2MPnDxr9p+f0O9Pxk8\nBA11xyaIe3fCvz4P/74Fbn3drRyKiIhIm2nFT6QdavYfZkFZNR9trGZB2S4Wb97N4Qa3itGnawqj\ne2cwKt/tE8zPTMaES1OP4z1/M2yeD3X7IbvIDR2PNlXr3fiKS++DMXe0fM3aGfD8F6BzN7jppchv\nfBNsy1+Gf98MY74El/7O62hEREQ6PK34iQSJLzmBCwZ254KB3QE4WNfAsi27jySCb67Yzr9KNgOQ\n1TmBot4ZFPn3CQ7NTguffYK+XFjxMphYuOiXXkfjjcy+kF7gkruWEr9Fz8G0u6D7YLcimto99DFG\nmsFXwua74IM/Q95YGHK11xGJiIiELSV+IgGUFB9LUX4GRfkZQF8aGy3rK/ZSUub2CJZsrOaN5dsB\nSE+O57z+3bhgYHfOPi2L1KQOPNetqbPnqFug20BPQ/FU4SQ3zqDuIMQnuWPWwryHYMaPoOAcuP4f\nkNTF2zgjycSfwpYSmP516D4Uup7mdUQiIiJhSaWeIiG2c89B5pfuYtaqncxavZPq/XXExxrGFGRw\nwYDuXDiwO3mZyV6HeazKdTDj/1xHx5Qsr6PxztqZ8MzVcNOL0O9CaGyEt37oVqQGXwVXPXLqc/7k\n0+3ZCg+f5X7v3fEOJKR4HZGIiEiHdLJSTyV+Ih5qaLQs3FTNzJU7eHvlTtbt3AtAYbfOXDCwOxcO\n7MbIvPTwKQmNdHUH4LcFMOpmmPhzmPZVWPpvtwft4t9ATIzXEUau9bNcZ9Wh18JnpkK47pcVEREJ\nIiV+ImGirGofb6/cydurdjB/wy7qG214lYRGg2eug4pVrqPlhllwwY/cXDslIsE3+16Y9Qu47H4Y\nfbvX0YiIiHQ4SvxEwtCeg3UUr6ng7ZWuJLTGXxI6tiCTCwZ244IBHbAkNBp8+Ci89h3X6GbyQzDy\nJq8jih6NjfDsdVA6G257E7JP9zoiERGRDkWJn0iYq29oZOGmGt5epZJQz9XugBdvh/Ffg/4Xex1N\n9Nm/Cx45GzDwpdmQnOF1RCIiIh2GEj+RCFNWtY+ZK3fy9sodfFjqSkIzUhI4t39XzirMYliOj4LM\nFGKUCEok2rIAHrsI+p4HN/5LeytFRET8lPiJRLCWSkIBUhPjGJKdxrCcNIbl+BiWk0ZOeqfwHSIv\n0lxTye35P4Szv+t1NCIiIh2CEj+RKNHQaFm3cy+Ly2tYWr6bJeU1rNxWy+GGRsDNDhya42NYs4Sw\ne5dEJYMSfqyFl+6AZS/C5/8Dfc71OiIRERHPKfETiWKH6xtZvb2WJVtcMri4fDdrdtTS0Oj+7HdN\nTWR4ThpDs33+ZDCNzM6aRSdh4NBeePR82F8FX54DXXp5HZGIiIinlPiJyDEO1jWwfOselpbXsGTL\nbpaU72Z9xV6a/neQ7evEsJw0huakMTzHx5DsNNI6aYyEdEAVq2HqedBjKNzyKsTq96mIiEQvJX4i\n8qn2Hqpn2ZbdrkR0iysTLavaf+R8QVYK4/pkcma/TMb3ydSqoHQcS1842mn1ol96HY2IiIhnTpb4\nxYU6GBHpmDonxjGuTybj+mQeOVaz/zBL/SuCH2+q5tXFW3nuw00ADOiRypn9sjizXyZjCjLpnKj/\nnYhHhl4Dm+fD+3+C3LEwaLLXEYmIiHQ4WvETkVarb2hk6ZbdzFtfxdx1lZSUVXO4vpG4GMPwXB9n\n9M3kjL5ZnN7bR2JcrNfhSjSpPwRPXAKVa+HOdyGzr9cRhQdrQc2dREQihko9RSQoDtY1sLCsmrnr\nK5m7rool5TU0WkiKj2F0fgZn9HUrgoN7pWm4vARfzWZ45Czokv3/27vzKLmOwt7j3+q9p3v2GY2W\n0UjWarAdbwIvGEIg57aipgAAIABJREFUGDAEk+CwJAFDSICcBMh5SV7IW/ICCTl5eUkeEHIghkBM\nYgLEhgB5CbYDPsTgfcWbZGtkjaSRNKtm6X2r90fd7ukZjcaSpZ5e5vc5p8+9Xff27Zq5uqP+ddWt\ngvffCaG2eteosT16C9z5h3DtH8Mlv1Tv2oiIyDmg4Cciq2Iuk+f+A9PcMzzJPfun2Dc2D0BHJODd\nH+iC4Pb+uKaQkNp47j/glhtckLn+b9SatZx8Bv79v8IjN0O4A3JJ+KWvw87X1btmIiJylhT8RKQu\nJuazlRD44+FJjpxIA7CuPcwrdvRx1XYXBjd1RetcU2kpd/0p/PB/w1v+Gi57T71r01hOHIRvvAeO\nPQ6v/B24+iNw85th6oAbFXXTZfWuoYiInAUFPxFpCIenU/x4/yQ/Hp7i3uFJJhM5wE0sP9QbY2tv\nG1t6Y2zpaWNrn1vvjYXUOihnplSEf3wbjNwDv3YnbLi43jVqDM/e7ia9t8Av/C3sfqMrnz8OX3wd\nFNKui2zPeXWtpoiIvHgKfiLScKy17Bub597hKfaPJxiZSjEynWT0RJpS1Z+lWMjPlt4YW/vaGOqp\nCoe9bazviODTvYOynOQkfP6VEAjBB34I0a5616h+SkXXCnr3X8D6n4K3f+XkcDfxLHzpWoj2wPvv\ngFhffeoqIiJnpaGCnzFmN/D1qqJtwB9aaz9VtY8BPg1cB6SA91prH1npuAp+Iq0hVyhx5ESKkekU\nI5NJDk6lGJlKMjKd4vB0inxx4W9WKOBjS08bW6rC4Bav5XBTV5SA31fHn0Tq7vADbqTPna+Hd96y\nNu/3S07Crb8Kz/8QLn03XPd/IHiKrtWH7oOvXA8DF8KN39XgOCIiTaihgt+iNzfGD4wCV1hrR6rK\nrwM+jAt+VwCfttZesdKxFPxEWl+xZDk6k660Do5MpTg4meTQdIqDU0ky+VJlX7/PMNTTxu6Bdnav\nb+f89e2cv6GDoZ42jTC6ltz3Ofjex+BnPw7X/Ha9a7O6Dj8A37gR0tNw3V/AZe9+4dc886/wjXe7\nsPyOfwS/5ucUEWkmjTyB+2uB4erQ57ke+Ip1qfQ+Y0yXMWaDtfbY6ldRRBqF32fY3NPG5p42rmFx\nVzRrLePzWQ5OutbBkakkw+NJ9o3Nc/vTxyl/xxUJ+tg10M7uARcEz1/vgmFfPFyHn0hq7ooPuZas\n738CBvfA1mvqXaPasxbu/1u4479D56Drunm69zm+5M3wxj+Hf/td+LffgTd/am22lIqItKB6B793\nAv+0TPkm4HDV8yNemYKfiCzLGMNAR4SBjghXbOtdtC2VK/DcWIJ9x+fZe3yefWNz3LVvnH9++Ehl\nn754yGsZ7Ki0EO5c1040pInom5oxbnTPsSddl8cP/ie0r693rWonOw/f+TA89S3YfR289XNnfn/j\ny38d5o7Cj/4KOgbhp3+vNnUVEZFVVbfgZ4wJAW8B/uAsjvEB4AMAQ0ND56hmItJq2kIBLt7cxcWb\nF38AnpjPemFwjn3H59k3Ns8t949UuowaA1t7Y17rYLvXOqjuok0n0gFv/wf4wmvg1vfDe77dml0Y\nx/e6bppT++Fn/wiu/ij4XuR9rq/9Qxf+7voT6NgAl/7KuaypiIjUQT3/53sj8Ii1dmyZbaPA5qrn\ng17ZItbam4CbwN3jV4tKikjr6m8P098e5pqdC91GiyXLoekUe4/NudZBLxBWdxeNBv3sHIiza8CF\nwfKyvz2sqSca1cBL4ec+Bd/6IPzgj+F1H693jc6tJ26F73zEDcjynm/Dea86u+OVW0oTY+648QFN\n8C4i0uTqNriLMeZrwO3W2i8vs+1NwG+xMLjLZ6y1L1/peBrcRURqKZ0r8tz4PHuPue6iz465QDgx\nn63s09UWPCkM7hxopzMarGPNZZHv/jY8/GXo2QY7r3VhZss1EIzUu2YvTiHn7uV74CbYfCX84t+7\nFrpzJTvvRkbVBO8iIk2h4Ub1NMbEgEPANmvtrFf2IQBr7ee96Rw+C7wBN53D+6y1K6Y6BT8RqYfp\nZM61Ch6fY99YgmfH5nn2+Dzz2UJlnw2dEXavb6+MMLproJ0d6+JEgrp/cNUVcvDoV9xk5s//JxQy\nEIjCtp92IXDH66B7S71reXpmj8A/vxeOPAhX/qZrxfTX4EsGTfAuItI0Gi741YKCn4g0CmstR2cz\nLgweT1RC4fB4glzR3T/oM7C1L1YJg7sH2tm1vp2tvTHdP7ha8mk4+CN47g73OHHQlfftdiFw57Uw\ndJWbBL7RDP8Abvs1F2Sv/yxc8Nbavp8meBcRaQoKfiIiDaBQLHFwKlkVBt09hCPTqUX3D56/oZ0L\nNnZwwcZOLtjYwa6BdrUO1pq1blCU5+50IXDkx1DMQSgO21690C20Y2N961kqwd1/CXd9EvrPh3f8\nA/TtXJ331gTvIiINT8FPRKSBpXNF9o8n2Ht8jqePzfHU0TmeOTpX6S7q9xl2rovz0qow+NKNHXRE\ndO9gzWQTrivoc3e4MDjnTf0xcNFCa+Dgy1Z3dNDUtBuc5rk74KK3u8FqQrHVe3/QBO8iIg1OwU9E\npMmUSpbDJ1I8dXSOp47Oesu5RYPJDPW0eS2DC4FwXUeTDlLSyKyF8WcWQuChe8EWIdIJ21/rQuCO\nn4V4f+3qMPoIfONGmD8Gb/wz2PP++k2s/sAX3ATvl79XE7yLiDQYBT8RkRYxPp/hqaNzPF0VCEem\nUpXtffHwSWFwqKcNn+4bPHcyszB8F+y/0wXBhDcr0cZLoWvIBUUslf67i55XLVfatvQYh+93Uyr8\n4s0wePnq/ayn8h8fdxO8/8z/0ATvrejEiGtN1r2cIk1HwU9EpIXNZfI847UIllsI948nKJTc3/d4\nOMD2dXE6IgHaQn7aQuVl1Xo4QGxpWWWbtx70K0AuVSrB2BOuNXD/DyA9DXi/I2PcemXJ4ufL7rPc\nEujeCtd+EmK9q/jDrcBa+NaH4Cdfg+v/ZnUmeC+V4NhjMP60m46j/3xo66n9+64VhRzs/S489GU4\neDcYv7u/9aIb4Pw3Q6Sj3jUUkdOg4CcissZk8kWeG0tUWgWfn0ySzBVI54okcwVS2SKpXJF0vnhG\nx40G/QthMBggFvYz2N3G9v44O9a5x9a+NsIBDUbT8go5+Orb3b2Qv/T12kzwnpmDA3fBs97Iq8nx\nxdtj62Dd+S4E9u+G/pe49UYJyM3gxEF4+O/h0X+E5AR0bYHLb3RzOD55G8wcAn8Ydl0LF94Au14P\nwWi9ay0ip6DgJyIiyyqVLOl8cSEUZouk8wWS2SKpXIFUrkgyVySdK3jbiiSzCwEykS1wcDLF6Ey6\ncky/zzDUszgMlh/xsAYDaSm1mOB9cj88d7uba3HkHijlF+6n3PV62HgZzIzAxF4Y3+uWE/sgN79w\njFi/Fwa9QLiuHAjVdRGAYsEF6Yf+DvZ/37Us774O9rwPtr0GfD63n7VunsgnboWnvuWCd6gdzn8T\nXPg22P4ztZk7UkReNAU/ERGpqVSuwIGJJPvHEwuPiQQHJ5OVLqcA6zsilRC4fV2cHV447IuHMBok\npDmd7QTvhZybPuO5O1zYmx525f3nu4Fzdr0BNl+x8gii1sLcaFUQfMaFwfG9iwNhW6/XKlgOg14r\nYaxvbQxSM3cUHvkHeORm9/tq3wCX3QiXvQc6N6382mLBdQF98jZ45jvuXtdoD7z0etcddOjqhcAo\nInWj4CciInWRL5YYmUqxfzzB8MRCKByeSJDKLXQz7YwGXSBc0kq4sSuqCe2bwZlO8D4/5o2Sersb\nKCeXcN0Jz3ulmypi17XuvsazZa0LO+UgWN1KmJ1b2C/a44LgS94Cl7179afJqKVSyXWXfehLsO/f\n3Yi0218Le37VheoXMyVHIetaCp+81R0zn4L2jXDhL7iWwI2X1jZIWwuJcZg+4L4omBqG2cOuZbhz\nEDoG3bJzkwu3apWUNUTBT0REGkqpZDk2l1nUQjjstRJOJ3OV/cIBH+f1xdjeH2d7f4xt/XG298fZ\n1h8jpm6jjeXQ/fCVt8DABd4E71XhqVSCY4+6e/We/Z4bpAVcWNjlteqd96rVC1zWuqkxqoPg0Ufh\n+E8g0gUv+zW44oMQX7c69amF5CQ8dosbrOXE866189J3u/v3eradu/fJJV34e+JW2P8frmtuzzZ3\nP+BFN7hW1RfDWnfP4dTw4oA3fQCmn1/ckmv80LEJsrOuJbKa8UF8vQuBnYNuv87Bxeux/rXR4itr\ngoKfiIg0jelkrtIqeGAiwfBEkuGJBIenU1T1GmVDZ4Rt/eVQGK+sb+iMqNtovVQmeL8Wfv7zbuCX\nZ293014kxwHjJr7f9Xr3GLiwsT5wH7of7vkM7P1/4A/Bxe+Aqz4M/bvqXbPTY62bZ/KhL8HT34Zi\nDra8wrXuveTnIBCu7funpuGZ77qWwOfvBiwMXAQXvc21BHYNnVzf5OSSUFdeXybcdW9xobJnO/Ru\n99a3ueOWW/Wy8zA7CnNHYPaItz7qWgTL64XM4nr4w9Cx8eRAWF4Pt0Op4B7FvLeeh1Jx8fNi4TS3\nFdxzLES7XYtzW3nZ40J6KN5Y14Y0DQU/ERFpetlCkZGpFMPjCQ5MJhmuhMMk89lCZb+2kJ9t/TG2\n9blAuH2dW9/WHyMS1GijNVee4L2sMjDLG9xE980w4ubUMNz7WXjsqy4k7HojvOIjMHRVY34Yz8zC\n4193gW/iGQh3wiXvgsvf50Y9rYf54/DUv7gQeORBVzb4chi60gWyaS/cVXe5NX4X4iqhrirgVYe7\ns2EtpKa8UHjEC4XV66MwfxRs6ezf62z4gi4EVsJg1Xp1QKwui3aBr4n+xhWy7vc+c8idk3Uvdff2\nNvq9ota6VvTjT8JL31Lv2pxEwU9ERFqWtZaJ+Sz7vRA47LUSHphIMDqTrsyBbgxs6opyXl+MrrYQ\nndEAHZEgndEgHVFvWXkeoDMapD0S1D2GL8YDX3AtLDtf/8IDszSyxAQ8+EV44CY3R+OmPXD1h13r\nWb0/YFsLRx9xXTmfvM3dZ7fpcte6d8EvQKitvvWrduKgq+MTt7lutV1DLswtDXjnKtydrWIBEsdd\nCJw97H63vqCrm8/v1n0B9+/aFzjFtuWeBxavWwuZGddSmp52y9TUwnqlbHpxWalwioobF/6iPa6b\ncnzAPdoHXHfX6vW23toHrMyc+/3NHPaWhxY/T4yd/JpoN2y+ErZc5QYM2nAxBEK1recLKRbcfK2H\n7nMt6ofuW6j77x90dW4gCn4iIrImpXNFnp9McmAywfC4C4Uj0ylmUznmMgVm03mKpZX/H2wPB+jw\nwmFHJLBMUAxUnnfHQvTHw/TGQ7SFmjTsyMlyKXj8q3DPZ903/d3nwVW/CZf88uoFLGth8lk3subB\nH7lHcgKCbXDRL7qpGDZeujp1ORulUuO36DQya10raSUMnvCWU1VlU+5Li8SYe1S3qpYZ/0I4bF/v\nra/3guHA4vXlugiXu+nOHqoKdtXLQyffb+kPeV1oN0PXZugc8pabXXg69jgcugdG7l0Y3TcQhcE9\nsOVq1+I++DIIx8/977VaNgGjDy0EvcMPQj7ptnUNuXoMXemWfbsb7t+zgp+IiMgyrLWkckVm03nm\nMnlmU/lKIJxL5xfK03nm0gXmFj3Pk6wamXSptpCf3niI3liYvniYvniIPi8UlpcuJIbpigbxqWWx\n8ZWKsPdf4cefcR8Moz3w8l+Hl/06xPvP7XtZC1P73X2SlaDnTWDfsQm2vtKNgvqSn3PdaUVOJZda\nCIHzx92IqInjbnTdxNjCenICWCYXRLq8cDjgWirL4a6QXrxfqH0hyC1aegEvtu70Q9L8mNe6dq+b\nz3PsSdf91vhdK2A5CA5ddfbdx+fH4PB9C0Hv2E/c6LcYWH/hQtDbfOULT3vSABT8REREaiBfLDHv\nBcXZdJ4TyRwTiSxTiRyTiSxTiSxTyRwT8245ncwt28Lo9xl6YqFKQOyNlcOhe97fHmawO8rGrqha\nEhuBte5D4j2fgX3/BoEIXPwuuOq3oG/Hiz/m1LDXoue16pW7k7VvhK3XuKC39RrX4tiI9xpKcysW\nIDW5cjgsFVyrXdfQyQEv0lW7f5eZWdfyVm4RHH0Yilm3rW/3QtfQLVedPIhQtfIXKuUum4fudYMK\ngbuOB1/mteZd6dab8EsVBT8REZEGUCpZZtJ5JhNZ75Fjylt3YdELjMksk/M50vmTWxS724Js6o6y\nqcsFwU1d0Uoo3NQVpScW0qimq2nyObjnr+Hxr7lRNM9/E1z9ERi6YuXXWes+cFZ33Zw/5rbF13sh\nzwt6PdsU9ESqFbIw+shCEDx8/0KX1o5BLwh6j3za7XfIa9VLTbr9oj2Lu202wv2E54CCn4iISBNK\n5QpMzucYm89wdCbNkRNpjs6kGZ1JM3rCLVNLuptGg342dkXY6AXCTV1RNnVH2djplus7IgT8jXVP\nSktIjLtBYB78IqRPuBEsX/ER2H2dG+SjPBLg89VB76h7bXxgIeSd9yoFPZEzVSrC2FMLXUMP3Xvy\n4DHd5y25P29nS15nCn4iIiItyFrLbDrPES8EHq0KhOXnk4ncotf4DKzviCxqNdzQFWVjpwuLGzuj\ndEQDajV8sXJJePQWNx3EzIgbsXLjpe6D6Nyo2ye2bqHb5tZXQu+OlvwAKlI35S9aDt0PwagLe+3r\n612rVaHgJyIiskZl8sWTQ2FVODw+m6Gw5L7DWMjPhq4oGzojbOqKsqEzWmlF3OAFRM2J+AKKBdj7\nXTcS6OwR1/Vsq9d9s0VbGkSk/hT8REREZFnFkmUykeXoTJqjMxmOzbrl0Zk0x2bTjM5kmExkT3pd\nTyzExq6IC4VeGNzQFWWTV9bdFiIc8Gm0UhGRVbRS8NPQYCIiImuY32cY6Igw0BHh0lMMhpctFBmb\nzTLqhcGjM2mOzmY4NpPm0FSK+w5MMZ9ZflLpkN9HOOgjHPATCfoIB3xEgn7CgeqyJcugn0jALcNV\ny0jQT3s4wNa+GJu7o7pXUUTkDCj4iYiIyIrCAT9DvW0M9Z56svL5TJ5js5lKy+FsOk+2UCSTLy1a\nZgslsnm3zOSLTCULZKqeu+0lMoUiK3VKCvl9bO1rY3t/3D3WxdjeH2dbf5x4WB9vRESW0l9GERER\nOWvtkSDtkSC7BtrPyfGsteSLlkyh6IKgFwpn0zkOTCQZnkgyPJFg39g8dzw9tmh+xA2dES8Qxti+\nzgXDHevirGsPa9AaEVmzFPxERESk4RhjCAUMoYAPIou3Xb6lZ9HzXKHEoekk+8ddGHSPJLc9Mkoi\nu9AFNR4OuDDYH/cCYYwd6+IM9cTc+4iItDAFPxEREWlqoYCPHeva2bFucWujtZbx+SzD4wthcHgi\nwb0Hpvjmo6OV/fw+w1BPG+s7IvTGQ/TFw/TEQvTGQ/TGwvTFQ97zMB0RTXUhIs1JwU9ERERakjEL\nA9dcvaNv0bZEtsDzE9UthAkm5rM8fXSOyUSWuVMMVhP0GxcCY+GTQmJfrGo97ra3hfRRS0QaQ13+\nGhljuoAvAhcCFvhVa+29VdtfDXwbeN4r+qa19hOrXU8RERFpTfFwgIsGO7losHPZ7blCiROpHJOJ\nLFOJHFPJ8jLHVCLLdDLHZCLHwakkU4kcqVxx2eNEgj66oiHaQn4iQT9tIT/RkJ/oovUA0ZCPtlCA\naNCVVe+/sL54e3DJqKbWWqx1H6ystZQsWLyyqvWStd4+i19TqqxbOiJBzdUo0mLq9TXUp4HvWWtv\nMMaEgOWGCbvbWvvmVa6XiIiICKGAr9JaeDrSuWIlHLpQmK2ExNl0nnS+RDpXIJ0vksgWmJjPks4X\nSeWKZHJFUvniogFqToffmyOxHNjOtf72MJu6ogx2R9nUHWWwu43BqudqzRRpLqt+xRpjOoFXAe8F\nsNbmgNxq10NERETkXImG/AyG2hjsPvWUFyux1pIrlsjkSqTyBVK5IulckXTeLVO5Iul8gXSuRCpX\nIJ0rkikUMRiMAYPr2urWDT6DW68qMwZXXn6NMd7rwGcWjoMxnEjmOHIixehMmidGZ7n9qePki4vT\nZU8stBAMK4GwrRIMOyLBs/21isg5VI+vas4DJoAvG2MuBh4GPmqtTS7Z7ypjzOPAUeB3rbVPrXI9\nRURERFaFMYZwwE844KeTxgtMpZIbKGd0JsWRE+nKY3Qmzb6xeX6wd5xsobToNR2RwEIQ9IJhXzxM\nyVqKJestoWgtpVJ1ma0qq9petV91WbHkgnMo4CMc8BEJuq6x4YCPsLeMBP1EvOeVZdBHJOAnvGTp\n82nwHmlNxtaib8BKb2jMHuA+4BXW2vuNMZ8G5qy1/7Nqnw6gZK1NGGOuAz5trd25zLE+AHwAYGho\n6PKRkZHV+SFEREREpMJay2Qix+hMmtET6Upr4ZETC8+Tp7gP8nT4jOva6jMGv8/gNwafz1TKfAby\nxRKZfIlMoXhWXV9Dft+i0NjVFmR9R4T1nRE2dLruvxs6o6zvdGXxsLq8SuMwxjxsrd2z7LY6BL/1\nwH3W2q3e81cCH7PWvmmF1xwE9lhrJ0+1z549e+xDDz10jmsrIiIiImfLWstsOs9UMoffC2++SoDj\npLLqkOfzuqWeyXvli5ZMoUgmXySbL5EtFMlULTP5ItnC4uVy27P5IidSOY7NZhiby3AilT/p/drD\ngUoILAfEpSGxuy2oaUBkVawU/Fb9Kwpr7XFjzGFjzG5r7T7gtcDT1ft44XDMWmuNMS8HfMDUatdV\nRERERM6eMYauthBdbaFVea9QwBAK+M75fYaZfJGxuQzHZjMcn81wfM4tj82mOT6X5dmxCSbmsywd\npycU8C1qNVzfEWFdR4T2cIBYOEA8EiAe9hMLB4iFArRHXPnSkVtFzka92qY/DNzijeh5AHifMeZD\nANbazwM3AL9hjCkAaeCddrWbJkVEREREqkSCfrb0xtjSGzvlPoViiYlE1rUSznoh0QuIx2czPHpo\nhuOzGXLF0imPURYK+IiHA8TLAdELh9VlsXCgEiBjYT9xLzD6vNZU1xXWtZz6qrrGVsqX7rNcubce\n9uqj1svmtOpdPWtFXT1FREREpBmUu77OZwokcwWS2QKJbJFEpry+sFxYL5LI5klmi4u2nWoOyVoJ\n+X10x4J0t4XoiS08lnveGw/R1RYkHKjtnJDW2sr0KOVRcMuj3+ZL1s1XCXDS3JZUtlXmtWTxvJfl\nfVhabuGtl26qTKvSKBqqq6eIiIiIyFp2Lru+lkrWC4/FShgslkoUS26Ox/I8j+URU8vrJYv33K2X\n9y1ZS6lU/Xxh/0yuyHQqx4lkjqmkWz59bI7pZI6ZZe5/LIuHAy4MxkL0tAXpjoXorTwP0RkNkiuW\nvMBWJJ0rVK27eS5PLitUTXVydgP6vFhvvngDfl9tQ+25pOAnIiIiItKkfD5DeyRIe53nTSwUS8ym\n85xI5ZhK5DiRyjGdzDOdzDKd9MqTOSYTOZ4dSzCdzJHOn7q1MuAzREN+2kJ+2kIBokG33h4JMNAR\ndmUhP21eeTQU8Jbl1/iJBgOEAgaWzncJi+a3hKXzWVbvzylfH2qyezAV/ERERERE5KwE/D5642F6\n42F2rDu916RzbtTUmVSecNDnAlvQBbpQoLlCVTNQ8BMRERERkVUXDfmJhqJs7IrWuyprgqK0iIiI\niIhIi1PwExERERERaXEKfiIiIiIiIi1OwU9ERERERKTFKfiJiIiIiIi0OAU/ERERERGRFqfgJyIi\nIiIi0uIU/ERERERERFqcgp+IiIiIiEiLU/ATERERERFpccZaW+86nBPGmAlg5CwO0QdMnqPqVOsE\nZmtw3FoeuxnrrPPXvMcFnb9mPi403/nTv4vFdP5qf+xm+78Pmu93Uctj6/zV/ri1PHYznr+zscVa\n27/sFmutHi78PlSj495UwzrX5NhNWmedvyY9rs5fcx+3Gc+f/l3o/LVKnWt17prxd9GMddb5a+46\n1/L81eqhrp61990mPHYz1rlWmvF30WzHrSWdv9oft5aa8XfRjHWulWb8XTRjnWulGX8XzVjnWmnG\n30Uz1rmptExXz7NljHnIWrun3vWQF0fnr7np/DU3nb/mpvPXvHTumpvOX3NrxvOnFr8FN9W7AnJW\ndP6am85fc9P5a246f81L56656fw1t6Y7f2rxExERERERaXFq8RMREREREWlxaz74GWPeYIzZZ4zZ\nb4z5WL3rI2fOGHPQGPOEMeYxY8xD9a6PrMwY8yVjzLgx5smqsh5jzJ3GmOe8ZXc96yjLO8W5+yNj\nzKh3/T1mjLmunnWUUzPGbDbG3GWMedoY85Qx5qNeua6/JrDC+dM12ASMMRFjzAPGmMe98/dxr/w8\nY8z93ufQrxtjQvWuq5xshfP398aY56uuv0vqXdeVrOmunsYYP/As8DrgCPAg8C5r7dN1rZicEWPM\nQWCPtbYR51KRJYwxrwISwFestRd6ZX8OTFtr/8z7AqbbWvv79aynnOwU5+6PgIS19i/qWTd5YcaY\nDcAGa+0jxph24GHgrcB70fXX8FY4f29H12DDM8YYIGatTRhjgsCPgI8C/wX4prX2a8aYzwOPW2s/\nV8+6yslWOH8fAv7VWntrXSt4mtZ6i9/Lgf3W2gPW2hzwNeD6OtdJpKVZa/8TmF5SfD1ws7d+M+7D\njDSYU5w7aRLW2mPW2ke89XngGWATuv6awgrnT5qAdRLe06D3sMBrgHJo0PXXoFY4f01lrQe/TcDh\nqudH0B/RZmSBO4wxDxtjPlDvysiLMmCtPeatHwcG6lkZOWO/ZYz5idcVVN0Em4AxZitwKXA/uv6a\nzpLzB7oGm4Ixxm+MeQwYB+4EhoEZa23B20WfQxvY0vNnrS1ff5/0rr//a4wJ17GKL2itBz9pDddY\nay8D3gj8ptcdTZqUdf3Pm+5btDXsc8B24BLgGPCX9a2OvBBjTBy4Dfhta+1c9TZdf41vmfOna7BJ\nWGuL1tpLgEGx8Xj1AAADwklEQVRcr7Pz61wlOQNLz58x5kLgD3Dn8WVAD9DQ3eTXevAbBTZXPR/0\nyqSJWGtHveU48C3cH1NpLmPe/Svl+1jG61wfOU3W2jHvP8MS8AV0/TU0796U24BbrLXf9Ip1/TWJ\n5c6frsHmY62dAe4CrgK6jDEBb5M+hzaBqvP3Bq8LtrXWZoEv0+DX31oPfg8CO70RlULAO4Hv1LlO\ncgaMMTHvJneMMTHgWuDJlV8lDeg7wI3e+o3At+tYFzkD5cDg+Xl0/TUsb3CCvwOesdb+VdUmXX9N\n4FTnT9dgczDG9Btjurz1KG5gwWdwAeIGbzddfw3qFOdvb9WXZgZ3f2ZDX39relRPAG/Y408BfuBL\n1tpP1rlKcgaMMdtwrXwAAeCrOoeNzRjzT8CrgT5gDPhfwL8A3wCGgBHg7dZaDSLSYE5x7l6N62Jm\ngYPAB6vuF5MGYoy5BrgbeAIoecX/DXefmK6/BrfC+XsXugYbnjHmp3CDt/hxDS/fsNZ+wvsc8zVc\nN8FHgV/xWo+kgaxw/n4A9AMGeAz4UNUgMA1nzQc/ERERERGRVrfWu3qKiIiIiIi0PAU/ERERERGR\nFqfgJyIiIiIi0uIU/ERERERERFqcgp+IiIiIiEiLU/ATERFZwhhTNMY8VvX42Dk89lZjTEPP9SQi\nIq0nUO8KiIiINKC0tfaSeldCRETkXFGLn4iIyGkyxhw0xvy5MeYJY8wDxpgdXvlWY8wPjDE/McZ8\n3xgz5JUPGGO+ZYx53Htc7R3Kb4z5gjHmKWPMHcaYaN1+KBERWRMU/ERERE4WXdLV8x1V22attRcB\nnwU+5ZX9NXCztfangFuAz3jlnwF+aK29GLgMeMor3wn8jbX2AmAGeFuNfx4REVnjjLW23nUQERFp\nKMaYhLU2vkz5QeA11toDxpggcNxa22uMmQQ2WGvzXvkxa22fMWYCGLTWZquOsRW401q703v++0DQ\nWvsntf/JRERkrVKLn4iIyJmxp1g/E9mq9SK6515ERGpMwU9EROTMvKNqea+3fg/wTm/9l4G7vfXv\nA78BYIzxG2M6V6uSIiIi1fQNo4iIyMmixpjHqp5/z1pbntKh2xjzE1yr3bu8sg8DXzbG/B4wAbzP\nK/8ocJMx5v24lr3fAI7VvPYiIiJL6B4/ERGR0+Td47fHWjtZ77qIiIicCXX1FBERERERaXFq8RMR\nEREREWlxavETERERERFpcQp+IiIiIiIiLU7BT0REREREpMUp+ImIiIiIiLQ4BT8REREREZEWp+An\nIiIiIiLS4v4/D4fMRNA34hEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA7Vki4-QAQx",
        "colab_type": "code",
        "outputId": "501b07ed-b716-42c5-b51d-8d9d23efd3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  return round(lr * 1/(1 + decay_factor * epoch), 10)\n",
        "\n",
        "lr = 0.007\n",
        "decay_factor = 0.004\n",
        "epoch = 100\n",
        "for i in range(epoch):\n",
        "  lr_new = scheduler(i, lr)\n",
        "  lr = lr_new\n",
        "  if i%5 == 0:\n",
        "    print(\"the epoch number is: \" + str(i) + \" and LR is: \" + str(round(lr,10)))\n",
        "  i = i+1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the epoch number is: 0 and LR is: 0.007\n",
            "the epoch number is: 5 and LR is: 0.0065952219\n",
            "the epoch number is: 10 and LR is: 0.005634606\n",
            "the epoch number is: 15 and LR is: 0.0043733703\n",
            "the epoch number is: 20 and LR is: 0.0030893887\n",
            "the epoch number is: 25 and LR is: 0.0019897041\n",
            "the epoch number is: 30 and LR is: 0.0011702877\n",
            "the epoch number is: 35 and LR is: 0.0006296332\n",
            "the epoch number is: 40 and LR is: 0.0003103498\n",
            "the epoch number is: 45 and LR is: 0.0001403585\n",
            "the epoch number is: 50 and LR is: 5.83287e-05\n",
            "the epoch number is: 55 and LR is: 2.23045e-05\n",
            "the epoch number is: 60 and LR is: 7.859e-06\n",
            "the epoch number is: 65 and LR is: 2.5548e-06\n",
            "the epoch number is: 70 and LR is: 7.673e-07\n",
            "the epoch number is: 75 and LR is: 2.132e-07\n",
            "the epoch number is: 80 and LR is: 5.48e-08\n",
            "the epoch number is: 85 and LR is: 1.31e-08\n",
            "the epoch number is: 90 and LR is: 2.9e-09\n",
            "the epoch number is: 95 and LR is: 6e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1WB81PaN2ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgYCMe1chjKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}